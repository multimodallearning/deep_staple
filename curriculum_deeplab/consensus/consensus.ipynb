{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Recommended gpus on this machine (descending order) ###\n",
      "  ID  Card name      Util    Mem free  Cuda             User(s)\n",
      "----  -----------  ------  ----------  ---------------  ---------\n",
      "   0  TITAN RTX       0 %   24199 MiB  11.2(460.73.01)  root\n",
      "\n",
      "Will apply following mapping\n",
      "\n",
      "  ID  Card name        torch\n",
      "----  -----------  --  -------\n",
      "   0  TITAN RTX    ->  cuda:0\n"
     ]
    }
   ],
   "source": [
    "# https://towardsdatascience.com/how-to-use-the-staple-algorithm-to-combine-multiple-image-segmentations-ce91ebeb451e\n",
    "# packages\n",
    "import nibabel as nib # https://nipy.org/nibabel/\n",
    "import SimpleITK as sitk # https://simpleitk.org/\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from meidic_vtach_utils.run_on_recommended_cuda import get_cuda_environ_vars as get_vars\n",
    "os.environ.update(get_vars(select=\"*\"))\n",
    "from collections import OrderedDict\n",
    "from mdl_seg_class.metrics import dice3d\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from ants.segmentation.joint_label_fusion import joint_label_fusion\n",
    "from ants.utils.convert_nibabel import nifti_to_ants\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calc deeds STAPLE scores (not used anymore, futher down scores and consensi are generate from the LRASPP training output directly. This ensures data consistency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108r\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 26\n",
      "111l\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 26\n",
      "112r\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 30\n",
      "115l\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 27\n",
      "118r\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 20\n",
      "120r\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 46\n",
      "117l\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 20\n",
      "123r\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 17\n",
      "127r\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 26\n",
      "125l\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 19\n",
      "134r\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 33\n",
      "135r\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 18\n",
      "126l\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 41\n",
      "142r\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 15\n",
      "144r\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 16\n",
      "133l\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 21\n",
      "148r\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 30\n",
      "154r\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 32\n",
      "136l\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 22\n",
      "160r\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 32\n",
      "165r\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 28\n",
      "140l\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 18\n",
      "166r\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 17\n",
      "167r\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 23\n",
      "141l\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 21\n",
      "168r\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 63\n",
      "171r\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 73\n",
      "143l\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 20\n",
      "173r\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 37\n",
      "174r\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 14\n",
      "145l\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 42\n",
      "179r\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 14\n",
      "146l\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 26\n",
      "180r\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 25\n",
      "181r\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 13\n",
      "185r\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 40\n",
      "147l\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 84\n",
      "195r\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 30\n",
      "149l\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 24\n",
      "198r\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 19\n",
      "204r\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 18\n",
      "152l\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 27\n",
      "205r\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 14\n",
      "209r\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 31\n",
      "158l\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 20\n",
      "210r\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 37\n",
      "162l\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 32\n",
      "164l\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 20\n",
      "175l\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 49\n",
      "177l\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 46\n",
      "178l\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 20\n",
      "183l\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 23\n",
      "187l\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 25\n",
      "188l\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 18\n",
      "189l\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 19\n",
      "190l\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 74\n",
      "192l\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 75\n",
      "199l\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 22\n",
      "200l\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 23\n",
      "202l\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "iters 40\n"
     ]
    }
   ],
   "source": [
    "# Load all 1800 registered labels\n",
    "REG_DATA_PATH = \"/share/data_supergrover1/weihsbach/shared_data/important_data_artifacts/curriculum_deeplab/20220114_crossmoda_multiple_registrations/crossmoda_deeds_registered.pth\"\n",
    "bare_data = torch.load(REG_DATA_PATH)\n",
    "\n",
    "EVERY = 1\n",
    "staple_filter = sitk.STAPLEImageFilter()\n",
    "# sitk.ProcessObject.SetGlobalDefaultDebugOff()\n",
    "FOREGROUND = 1.0\n",
    "staple_filter.SetMaximumIterations(200) # Do not forget this, otherwise staple runs forever\n",
    "staple_filter.SetForegroundValue(FOREGROUND)\n",
    "\n",
    "weight_data = {}\n",
    "DEBUG = False\n",
    "\n",
    "for fixed_id, moving_dict in bare_data.items():\n",
    "    # if fixed_id != '111l': continue\n",
    "    print(fixed_id)\n",
    "    # print(moving_dict)\n",
    "    sorted_moving_dict = OrderedDict(moving_dict)\n",
    "    moving_data = []\n",
    "    selected_moving_ids = []\n",
    "    \n",
    "    for idx_mov, (moving_id, moving_sample) in enumerate(sorted_moving_dict.items()):\n",
    "        # Only use every third warped sample\n",
    "        print(idx_mov)\n",
    "        # idx_mov = 29\n",
    "        if idx_mov % EVERY == 0:\n",
    "            moving_data.append(moving_sample['warped_label'].cpu())\n",
    "            moving_slice_id = f\"{fixed_id}:m{moving_id}\"\n",
    "            selected_moving_ids.append(moving_slice_id)\n",
    "\n",
    "    sitk_moving_data = [sitk.GetImageFromArray(reg_seg.to_dense().numpy().astype(np.int16)) for reg_seg in moving_data]\n",
    "    staple_out = staple_filter.Execute(sitk_moving_data)\n",
    "    # staple_out = sitk.STAPLE(sitk_moving_data, FOREGROUND) # alternative, if no staple filter instance is used\n",
    "    staple_consensus = sitk.GetArrayFromImage(staple_out)\n",
    "    \n",
    "    specitivity = staple_filter.GetSpecificity()\n",
    "    sensitivity = staple_filter.GetSensitivity()\n",
    "    print(\"iters\", staple_filter.GetElapsedIterations())\n",
    "\n",
    "    for moving_id, sens, spec in zip(selected_moving_ids, sensitivity, specitivity):\n",
    "        weight_data[moving_id] = dict(sensitivity=sens, specitivity=spec)\n",
    "\n",
    "    if DEBUG: break\n",
    "\n",
    "torch.save(weight_data, f\"../data/staple_calc/deeds_stapled_every_{EVERY}_3d_volumes.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print sensitivity histogram\n",
    "dps = []\n",
    "for key in weight_data.keys():\n",
    "    if key == 'data_path': continue\n",
    "    if np.isnan(weight_data[key]['sensitivity']):\n",
    "        pass\n",
    "    else:\n",
    "        dps.append(weight_data[key]['sensitivity'])\n",
    "plt.hist(dps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process grouped STAPLED samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store STAPLE single rater scores (grouped stapled command line data from mattias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import re\n",
    "\n",
    "staple_weights = None\n",
    "staple_description_files = glob(\"/share/data_supergrover1/heinrich/crossmoda_deeds/Fcrossmoda_*_L_staple*.txt\")\n",
    "\n",
    "target_t2_keys_w_tumour = ['108r', '111l', '112r', '115l', '118r', '120r', '117l', '123r', '127r', '125l', '134r', '135r', '126l', '142r', '144r', '133l', '148r', '154r', '136l', '160r', '165r', '140l', '166r', '167r', '141l', '168r', '171r', '143l', '173r', '174r', '145l', '179r', '146l', '180r', '181r', '185r', '147l', '195r', '149l', '198r', '204r', '152l', '205r', '209r', '158l', '210r', '162l', '164l', '175l', '177l', '178l', '183l', '187l', '188l', '189l', '190l', '192l', '199l', '200l', '202l']\n",
    "source_t1_keys_w_tumour = ['100r', '101r', '102l', '103l', '104l', '105l', '010l', '011r', '012r', '013l', '014l', '015l', '016r', '017r', '018l', '019r', '001r', '020l', '021l', '022l', '023r', '024r', '025r', '026l', '027r', '028l', '029r', '002l', '030r', '031l', '032r', '033r', '034l', '035r', '036r', '037r', '038l', '039r', '003r', '040r', '041l', '042l', '042r', '043l', '044r', '045r', '046r', '047r', '048r', '049l', '004r', '050r', '051l', '052r', '053r', '054r', '055l', '056l', '057r', '058l', '059r', '005r', '060r', '061l', '062l', '063l', '064l', '065r', '066l', '067l', '068r', '069l', '006r', '070r', '071l', '072r', '073r', '074r', '075l', '076r', '077r', '078r', '079l', '007r', '080r', '081l', '082r', '083r', '084r', '085r', '086r', '087l', '088l', '089l', '008l', '090l', '091r', '092r', '093l', '094r', '095r', '096r', '097r', '098r', '099l', '099r', '009r']\n",
    "\n",
    "def get_num_lr_id(num_str):\n",
    "    num_str = int(num_str)\n",
    "    if f\"{num_str:03d}r\" in source_t1_keys_w_tumour:\n",
    "        _id_str = f\"{num_str:03d}r\"\n",
    "    elif f\"{num_str:03d}l\" in source_t1_keys_w_tumour:\n",
    "        _id_str = f\"{num_str:03d}l\"\n",
    "    elif f\"{num_str:03d}r\" in target_t2_keys_w_tumour:\n",
    "        _id_str = f\"{num_str:03d}r\"\n",
    "    elif f\"{num_str:03d}l\" in target_t2_keys_w_tumour:\n",
    "        _id_str = f\"{num_str:03d}l\"\n",
    "    return _id_str\n",
    "\n",
    "def get_rater_dict(fixed_id, moving_id, rater_id):\n",
    "    fixed_id_dict = consensus_description_dict.get(fixed_id, {}) \n",
    "    moving_id_dict = fixed_id_dict.get(moving_id, {})\n",
    "    rater_dict = moving_id_dict.get(f\"rater_{int(rater_id):03d}\", {})\n",
    "    return rater_dict\n",
    "\n",
    "def set_rater_dict(consensus_description_dict, rater_dict, fixed_id, moving_id, rater_id):\n",
    "    fixed_id_dict = consensus_description_dict.get(fixed_id, {})\n",
    "    fixed_id_dict[moving_id] = rater_dict\n",
    "    consensus_description_dict[fixed_id] = fixed_id_dict\n",
    "\n",
    "consensus_description_dict = {}\n",
    "\n",
    "for _file in staple_description_files:\n",
    "    for staple_split in ['01','23','45','689']:\n",
    "        result = re.findall(rf'/share/data_supergrover1/heinrich/crossmoda_deeds/Fcrossmoda_(\\w+)_L_staple{staple_split}\\.txt', _file)\n",
    "        if not result: \n",
    "            continue\n",
    "        else:\n",
    "            intra_file_dict = {}\n",
    "            with open(_file, 'r') as description:\n",
    "                for line in description:\n",
    "                    # print(line)\n",
    "                    seg_info = re.findall(rf'Reading #([0-9]+) from (Fcrossmoda_(\\w+)_L_M(\\w+)_deformed_seg\\.nii\\.gz)', line)\n",
    "                    if seg_info:\n",
    "                        rater_id, seg_path, fixed_id, moving_id = seg_info[0]\n",
    "                        fixed_id, moving_id = get_num_lr_id(fixed_id), get_num_lr_id(moving_id)\n",
    "                        # print(fixed_id, moving_id)\n",
    "                        rater_dict = get_rater_dict(fixed_id, moving_id, rater_id)\n",
    "                        rater_dict['file'] = seg_path\n",
    "                        rater_dict['fixed_id'] = fixed_id\n",
    "                        rater_dict['moving_id'] = moving_id\n",
    "                        intra_file_dict[int(rater_id)-1] = rater_dict\n",
    "\n",
    "                        set_rater_dict(consensus_description_dict, rater_dict, fixed_id, moving_id, rater_id)\n",
    "\n",
    "                    rater_info = re.findall(rf'Rater ([0-9]+): Sensitivity = ([\\.\\-\\w]+); Specificity = ([\\.\\w]+)', line)\n",
    "                    if rater_info:\n",
    "                        score_rater_id, sensitivity, specitivity = rater_info[0]\n",
    "\n",
    "                        score_rater_dict = intra_file_dict[int(score_rater_id)]\n",
    "                        score_fixed_id = score_rater_dict['fixed_id']\n",
    "                        score_moving_id = rater_dict['moving_id']\n",
    "                        score_rater_dict['sensitivity'] = float(sensitivity)\n",
    "                        score_rater_dict['specitivity'] = float(specitivity)\n",
    "                        set_rater_dict(consensus_description_dict, score_rater_dict, score_fixed_id, score_moving_id, score_rater_id)\n",
    "                        # print(rater_id, sensitivity, specitivity)\n",
    "print(consensus_description_dict.keys())\n",
    "\n",
    "torch.save(consensus_description_dict, \"../data/staple_calc/crossmoda_grouped_staple_consensus_text_dict.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store STAPLED samples (data from mattias, store stapled hard drive labels into dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import re\n",
    "import nibabel as nib\n",
    "staple_descri = glob(\"/share/data_supergrover1/heinrich/crossmoda_deeds/Fcrossmoda_*_L_staple*.nii.gz\")\n",
    "stapled_files = glob(\"/share/data_supergrover1/heinrich/crossmoda_deeds/Fcrossmoda_*_L_staple*.nii.gz\")\n",
    "\n",
    "staple_dict = {}\n",
    "target_t2_keys_w_tumour = ['108r', '111l', '112r', '115l', '118r', '120r', '117l', '123r', '127r', '125l', '134r', '135r', '126l', '142r', '144r', '133l', '148r', '154r', '136l', '160r', '165r', '140l', '166r', '167r', '141l', '168r', '171r', '143l', '173r', '174r', '145l', '179r', '146l', '180r', '181r', '185r', '147l', '195r', '149l', '198r', '204r', '152l', '205r', '209r', '158l', '210r', '162l', '164l', '175l', '177l', '178l', '183l', '187l', '188l', '189l', '190l', '192l', '199l', '200l', '202l']\n",
    "\n",
    "for _file in stapled_files:\n",
    "    for staple_split in ['01','23','45','689']:\n",
    "    # result = re.findall(r'/share/data_supergrover1/heinrich/crossmoda_deeds/Fcrossmoda_(\\w+)_L_staple([0-9]+)\\.nii\\.gz', _file)\n",
    "        result = re.findall(rf'/share/data_supergrover1/heinrich/crossmoda_deeds/Fcrossmoda_(\\w+)_L_staple{staple_split}\\.nii\\.gz', _file)\n",
    "        if not result: \n",
    "            continue\n",
    "        else:\n",
    "            fixed_num_str = result[0]\n",
    "        \n",
    "        \"/share/data_supergrover1/heinrich/crossmoda_deeds/Fcrossmoda_*_L_staple{01,23,45,689}.nii.gz\"\n",
    "        if fixed_num_str+'r' in target_t2_keys_w_tumour:\n",
    "            fixed_id = fixed_num_str+'r'\n",
    "        elif fixed_num_str+'l' in target_t2_keys_w_tumour:\n",
    "            fixed_id = fixed_num_str+'l'\n",
    "        split_dict = staple_dict.get(fixed_id, {})\n",
    "        split_dict[staple_split] = dict(\n",
    "            warped_label=torch.tensor(nib.load(_file).get_fdata()).long().to_sparse(),\n",
    "            file_path=_file\n",
    "        )\n",
    "        staple_dict[fixed_id] = split_dict\n",
    "        print(staple_split, fixed_id)\n",
    "    \n",
    "torch.save(staple_dict, \"../data/staple_calc/crossmoda_grouped_staple_consensus.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare grouped STAPLE scores to network scores (not used anymore, futher down scores and consensi are generate from the LRASPP training output directly. This ensures data consistency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_staple_scores = torch.load(\"/share/data_supergrover1/weihsbach/shared_data/important_data_artifacts/curriculum_deeplab/20220120_crossmoda_staple/grouped_staple_consensus_text_dict.pth\")\n",
    "\n",
    "# Training with 400 labels\n",
    "network_scores = torch.load(\"/share/data_supergrover1/weihsbach/shared_data/important_data_artifacts/curriculum_deeplab/swept-wind-1249_fold0_epx39/train_label_snapshot.pth\")\n",
    "\n",
    "# Training with 1200 labels\n",
    "# network_scores = torch.load(\"/share/data_supergrover1/weihsbach/shared_data/important_data_artifacts/curriculum_deeplab/classic-sunset-1245_fold0_epx39/train_label_snapshot.pth\")\n",
    "\n",
    "# Training with 1800 labels\n",
    "# network_scores = torch.load(\"/share/data_supergrover1/weihsbach/shared_data/important_data_artifacts/curriculum_deeplab/comic-sponge-1268_fold0_epx39/train_label_snapshot.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_ids = network_scores['d_ids']\n",
    "network_parameter = network_scores['data_parameters']\n",
    "\n",
    "staple_sensitivities = {}\n",
    "\n",
    "for fixed_id, moving_dict in grouped_staple_scores.items():\n",
    "    for moving_id, rater_dict in moving_dict.items():\n",
    "        if 'sensitivity' in rater_dict:\n",
    "            staple_sensitivities[f\"{fixed_id}:m{moving_id}\"] = rater_dict['sensitivity']\n",
    "        else:\n",
    "            print(\"No sensitivity value for id \", f\"{fixed_id}:m{moving_id}\")\n",
    "\n",
    "matching_ids = set(d_ids).intersection(set(staple_sensitivities.keys()))\n",
    "print(\"Matching ids #\", len(matching_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_matching_ids = set(d_ids).difference(set(staple_sensitivities.keys()))\n",
    "\n",
    "print(len(staple_sensitivities), len(d_ids))\n",
    "non_matching_ids\n",
    "\n",
    "# non_matching_ids_inv = set(staple_sensitivities.keys()).difference(set(d_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wise_dices = {}\n",
    "\n",
    "for _id in tqdm(d_ids):\n",
    "    network_data_lookup_idx = d_ids.index(_id)\n",
    "\n",
    "    registered_label = network_scores['modified_labels'][network_data_lookup_idx]\n",
    "    ground_truth = network_scores['labels'][network_data_lookup_idx]\n",
    "\n",
    "    wise_dices[_id] = dice3d(\n",
    "        torch.nn.functional.one_hot(registered_label.to_dense().unsqueeze(0), 2),\n",
    "        torch.nn.functional.one_hot(ground_truth.to_dense().unsqueeze(0), 2),\n",
    "        one_hot_torch_style=True, nan_for_unlabeled_target=False\n",
    "    )\n",
    "torch.save(wise_dices, \"wise_dices_400.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color mov/fixed ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "staple_scores = []\n",
    "data_params = []\n",
    "dices = []\n",
    "fcolors = []\n",
    "mcolors = []\n",
    "\n",
    "f_ids = set([_id[:4] for _id in d_ids])\n",
    "fid_colors = {_id: color for color, _id in enumerate(sorted(list(f_ids)))}\n",
    "\n",
    "m_ids = set([_id[6:] for _id in d_ids])\n",
    "mid_colors = {_id: color for color, _id in enumerate(sorted(list(m_ids)))}\n",
    "\n",
    "for _id in d_ids:\n",
    "    network_data_lookup_idx = d_ids.index(_id)\n",
    "    # staple_scores.append(staple_sensitivities[_id])\n",
    "    data_params.append(network_scores['data_parameters'][network_data_lookup_idx].cpu().detach())\n",
    "    dices.append(wise_dices[_id][0,1].item())\n",
    "    fcolors.append(fid_colors[_id[:4]])\n",
    "    mcolors.append(mid_colors[_id[6:]])\n",
    "\n",
    "dices = np.array(dices)\n",
    "staple_scores = np.array(staple_scores)\n",
    "data_params = np.array([dp.item() for dp in data_params])\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(16, 4), dpi=80)\n",
    "\n",
    "sc4 = axs[0].scatter(\n",
    "    data_params, \n",
    "    dices, c=fcolors, s=10, cmap='rainbow')\n",
    "sc5 = axs[1].scatter(\n",
    "    data_params, \n",
    "    dices, c=mcolors, s=10, cmap='rainbow')\n",
    "\n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.82, 0.15, 0.02, 0.7])\n",
    "fig.colorbar(sc5, cax=cbar_ax)\n",
    "\n",
    "axs[1].set_title(\"DP/dice c=mov_id\")\n",
    "\n",
    "plt.show()\n",
    "print(len(f_ids), len(m_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View initial quality of atlas dices (after registration) for deeds and convex adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "convex_atlases = torch.load(\"/share/data_supergrover1/weihsbach/shared_data/important_data_artifacts/curriculum_deeplab/20220318_crossmoda_convex_adam_lr/crossmoda_convex_registered_new_convex.pth\")\n",
    "deeds_atlases = torch.load(\"/share/data_supergrover1/weihsbach/shared_data/important_data_artifacts/curriculum_deeplab/20220114_crossmoda_multiple_registrations/crossmoda_deeds_registered.pth\")\n",
    "\n",
    "dcs_convex = []\n",
    "for fixed_item in convex_atlases.values():\n",
    "    for moving_item in fixed_item.values():\n",
    "        dcs_convex.append(moving_item['dice'][0][1].item())\n",
    "dcs_convex.sort()\n",
    "\n",
    "dcs_deeds = []\n",
    "for fixed_item in deeds_atlases.values():\n",
    "    for moving_item in fixed_item.values():\n",
    "        dcs_deeds.append(moving_item['dice'][0][1].item())\n",
    "dcs_deeds.sort()\n",
    "\n",
    "plt.plot(dcs_deeds, label='deeds')\n",
    "plt.plot(dcs_convex, label='convex')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create consensi (take training data directly and calculate consensi as well as dice values. Store data in a consistent dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull out data of network training and put into fixed-moving dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dp_consensus(lbl_list, weighting_list):\n",
    "    LIMIT = .5\n",
    "    label_stack = torch.stack(lbl_list)\n",
    "    weightings = torch.tensor(weighting_list)\n",
    "    weightings = torch.softmax(weightings, 0)\n",
    "    weighted_stack = label_stack.to_dense()*weightings.view(-1,1,1,1)\n",
    "    weighted_stack = weighted_stack.sum((0))\n",
    "    consensus = (weighted_stack > LIMIT).long()\n",
    "    # print()\n",
    "    # print(\"\")\n",
    "    # plt.imshow(weighted_stack.sum((-1)))\n",
    "    # plt.colorbar()\n",
    "    # plt.show()\n",
    "\n",
    "    # print()\n",
    "    # print(\"Consensus W sum\")\n",
    "    # plt.imshow(consensus.sum((-1)))\n",
    "    # plt.colorbar()\n",
    "    # plt.show()\n",
    "\n",
    "    return consensus\n",
    "\n",
    "\n",
    "def calc_staple_consensus(lbl_list, weighting_list):\n",
    "    staple_filter = sitk.STAPLEImageFilter()\n",
    "    weightings = torch.tensor(weighting_list)\n",
    "    weightings = torch.softmax(weightings, 0)\n",
    "    # sitk.ProcessObject.SetGlobalDefaultDebugOff()\n",
    "    FOREGROUND = 1.0\n",
    "    staple_filter.SetForegroundValue(FOREGROUND)\n",
    "    staple_filter.SetMaximumIterations(200)\n",
    "    sitk_moving_data = [sitk.GetImageFromArray(lbl.to_dense().numpy().astype(np.int16)) for lbl in lbl_list]\n",
    "    \n",
    "    staple_out = staple_filter.Execute(sitk_moving_data)\n",
    "    # staple_filter.SetConfidenceWeight(weightings.tolist())\n",
    "    consensus = (torch.tensor(sitk.GetArrayFromImage(staple_out)) > .5).long()\n",
    "\n",
    "    return consensus\n",
    "\n",
    "def calc_jlf_consensus(sample_group, target_img_path):\n",
    "    # see https://pubmed.ncbi.nlm.nih.gov/22732662/, Multi-Atlas Segmentation with Joint Label Fusion\n",
    "\n",
    "    def standardize_img(img: ants.ANTsImage):\n",
    "        # Image data is standardized with zero mean and unit variance, see paper p. 2\n",
    "        data = img.numpy()\n",
    "        data = data / np.std(data)\n",
    "        data = data - data.mean()\n",
    "\n",
    "        return img.new_image_like(data)\n",
    "\n",
    "    target_img = nifti_to_ants(nib.load(target_img_path))\n",
    "    target_img = standardize_img(target_img)\n",
    "\n",
    "    target_mask = ants.get_mask(target_img)\n",
    "    target_mask = ants.iMath(target_mask,'ME',2) # just to speed things up\n",
    "\n",
    "    ants_image_list = []\n",
    "    ants_seg_list = []\n",
    "\n",
    "    for img_path, seg_path in zip(group.images, group.labels):\n",
    "        # Build ants image list to feed it into jlf, \\\n",
    "        # loading nib first and converting to ants proved to be more stable compared to direct ants load\n",
    "        cur_img = nifti_to_ants(nib.load(img_path))\n",
    "        cur_seg = nifti_to_ants(nib.load(seg_path))\n",
    "\n",
    "        # Copy header info since ants is picky with spatial tolerances\n",
    "        # (could not find switch to increase tolerance setting)\n",
    "        cur_seg.set_origin(target_img.origin)\n",
    "        cur_img.set_origin(target_img.origin)\n",
    "        cur_seg.set_spacing(target_img.spacing)\n",
    "        cur_img.set_spacing(target_img.spacing)\n",
    "\n",
    "        cur_img = standardize_img(cur_img)\n",
    "\n",
    "        ants_image_list.append(cur_img)\n",
    "        ants_seg_list.append(cur_seg)\n",
    "\n",
    "    jlf_dict = joint_label_fusion(\n",
    "        target_image=target_img,\n",
    "        target_image_mask=target_mask,\n",
    "        atlas_list=ants_image_list,\n",
    "        beta=4,\n",
    "        rad=2,\n",
    "        label_list=ants_seg_list,\n",
    "        rho=0.01,\n",
    "        usecor=False,\n",
    "        r_search=2,\n",
    "        nonnegative=False,\n",
    "        no_zeroes=False,\n",
    "        max_lab_plus_one=True,\n",
    "        output_prefix=None,\n",
    "        verbose=True)\n",
    "\n",
    "    # Write out jlf image data and segmentation numbers (json)\n",
    "    for key, val in jlf_dict.items():\n",
    "        if key == 'segmentation_numbers':\n",
    "            seg_num_json_path = os.path.join(intermediate_dir, f\"{group_prefix}_segmentation_numbers.json\")\n",
    "            with open(seg_num_json_path, 'w') as fil:\n",
    "                json.dump(jlf_dict['segmentation_numbers'], fil)\n",
    "        elif key in ['intensity', 'segmentation']:\n",
    "            ants.image_write(jlf_dict[key], os.path.join(intermediate_dir,\n",
    "                f\"{group_prefix}_{key}.nii.gz\"))\n",
    "        elif key == 'probabilityimages':\n",
    "            dict_keys_w_o_background = list(class_id_dict.keys())[1:]\n",
    "            for prop_img, class_key in zip(val, dict_keys_w_o_background):\n",
    "                ants.image_write(prop_img, os.path.join(intermediate_dir,\n",
    "                    f\"{group_prefix}_{key}_{class_key}.nii.gz\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating consensus for 400_deeds\n",
      "Reading labels\n",
      "Getting consensus scores\n",
      "dict_keys(['147l', '143l', '146l', '192l', '149l', '177l', '178l', '175l', '140l', '188l', '183l', '152l', '202l', '141l', '189l', '200l', '205r', '162l', '145l', '199l', '158l', '179r', '187l', '190l', '204r', '165r', '167r', '174r', '185r', '166r', '164l', '198r', '209r', '195r', '181r', '171r', '168r', '180r', '173r', '210r'])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17c94b8394c64c1f91f42afb994bbf17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_id:  147l\n",
      "DP consensus dice: tensor([[0.9990, 0.8031]])\n",
      "STAPLE consensus dice: tensor([[0.9910, 0.3601]])\n",
      "\n",
      "f_id:  143l\n",
      "DP consensus dice: tensor([[0.9931, 0.6378]])\n",
      "STAPLE consensus dice: tensor([[0.9930, 0.7607]])\n",
      "\n",
      "f_id:  146l\n",
      "DP consensus dice: tensor([[0.9904, 0.5717]])\n",
      "STAPLE consensus dice: tensor([[0.9907, 0.6815]])\n",
      "\n",
      "f_id:  192l\n",
      "DP consensus dice: tensor([[0.9986, 0.7771]])\n",
      "STAPLE consensus dice: tensor([[0.9962, 0.5997]])\n",
      "\n",
      "f_id:  149l\n",
      "DP consensus dice: tensor([[0.9953, 0.6715]])\n",
      "STAPLE consensus dice: tensor([[0.9890, 0.5520]])\n",
      "\n",
      "f_id:  177l\n",
      "DP consensus dice: tensor([[0.9987, 0.8579]])\n",
      "STAPLE consensus dice: tensor([[0.9982, 0.8231]])\n",
      "\n",
      "f_id:  178l\n",
      "DP consensus dice: tensor([[0.9935, 0.6933]])\n",
      "STAPLE consensus dice: tensor([[0.9933, 0.6969]])\n",
      "\n",
      "f_id:  175l\n",
      "DP consensus dice: tensor([[0.9959, 0.6495]])\n",
      "STAPLE consensus dice: tensor([[0.9954, 0.6867]])\n",
      "\n",
      "f_id:  140l\n",
      "DP consensus dice: tensor([[0.9987, 0.8034]])\n",
      "STAPLE consensus dice: tensor([[0.9910, 0.4326]])\n",
      "\n",
      "f_id:  188l\n",
      "DP consensus dice: tensor([[0.9881, 0.5278]])\n",
      "STAPLE consensus dice: tensor([[0.9905, 0.7167]])\n",
      "\n",
      "f_id:  183l\n",
      "DP consensus dice: tensor([[0.9979, 0.8305]])\n",
      "STAPLE consensus dice: tensor([[0.9978, 0.8501]])\n",
      "\n",
      "f_id:  152l\n",
      "DP consensus dice: tensor([[0.9984, 0.7056]])\n",
      "STAPLE consensus dice: tensor([[0.9893, 0.2717]])\n",
      "\n",
      "f_id:  202l\n",
      "DP consensus dice: tensor([[0.9938, 0.6205]])\n",
      "STAPLE consensus dice: tensor([[0.9953, 0.7666]])\n",
      "\n",
      "f_id:  141l\n",
      "DP consensus dice: tensor([[0.9980, 0.1754]])\n",
      "STAPLE consensus dice: tensor([[0.9921, 0.0745]])\n",
      "\n",
      "f_id:  189l\n",
      "DP consensus dice: tensor([[0.9976, 0.2488]])\n",
      "STAPLE consensus dice: tensor([[0.9945, 0.1552]])\n",
      "\n",
      "f_id:  200l\n",
      "DP consensus dice: tensor([[0.9979, 0.3472]])\n",
      "STAPLE consensus dice: tensor([[0.9950, 0.1952]])\n",
      "\n",
      "f_id:  205r\n",
      "DP consensus dice: tensor([[0.9923, 0.7947]])\n",
      "STAPLE consensus dice: tensor([[0.9950, 0.8827]])\n",
      "\n",
      "f_id:  162l\n",
      "DP consensus dice: tensor([[0.9904, 0.5819]])\n",
      "STAPLE consensus dice: tensor([[0.9901, 0.6277]])\n",
      "\n",
      "f_id:  145l\n",
      "DP consensus dice: tensor([[0.9986, 0.8195]])\n",
      "STAPLE consensus dice: tensor([[0.9959, 0.6335]])\n",
      "\n",
      "f_id:  199l\n",
      "DP consensus dice: tensor([[0.9976, 0.5856]])\n",
      "STAPLE consensus dice: tensor([[0.9959, 0.4792]])\n",
      "\n",
      "f_id:  158l\n",
      "DP consensus dice: tensor([[0.9844, 0.5337]])\n",
      "STAPLE consensus dice: tensor([[0.9862, 0.6083]])\n",
      "\n",
      "f_id:  179r\n",
      "DP consensus dice: tensor([[0.9968, 0.8930]])\n",
      "STAPLE consensus dice: tensor([[0.9961, 0.8817]])\n",
      "\n",
      "f_id:  187l\n",
      "DP consensus dice: tensor([[0.9857, 0.5049]])\n",
      "STAPLE consensus dice: tensor([[0.9870, 0.5918]])\n",
      "\n",
      "f_id:  190l\n",
      "DP consensus dice: tensor([[0.9985, 0.7215]])\n",
      "STAPLE consensus dice: tensor([[0.9964, 0.5347]])\n",
      "\n",
      "f_id:  204r\n",
      "DP consensus dice: tensor([[0.9980, 0.5798]])\n",
      "STAPLE consensus dice: tensor([[0.9938, 0.3465]])\n",
      "\n",
      "f_id:  165r\n",
      "DP consensus dice: tensor([[0.9955, 0.5159]])\n",
      "STAPLE consensus dice: tensor([[0.9936, 0.4465]])\n",
      "\n",
      "f_id:  167r\n",
      "DP consensus dice: tensor([[0.9968, 0.8252]])\n",
      "STAPLE consensus dice: tensor([[0.9959, 0.8003]])\n",
      "\n",
      "f_id:  174r\n",
      "DP consensus dice: tensor([[0.9959, 0.8515]])\n",
      "STAPLE consensus dice: tensor([[0.9959, 0.8635]])\n",
      "\n",
      "f_id:  185r\n",
      "DP consensus dice: tensor([[0.9897, 0.6854]])\n",
      "STAPLE consensus dice: tensor([[0.9916, 0.7768]])\n",
      "\n",
      "f_id:  166r\n",
      "DP consensus dice: tensor([[0.9908, 0.6600]])\n",
      "STAPLE consensus dice: tensor([[0.9940, 0.8162]])\n",
      "\n",
      "f_id:  164l\n",
      "DP consensus dice: tensor([[0.9947, 0.6763]])\n",
      "STAPLE consensus dice: tensor([[0.9949, 0.7166]])\n",
      "\n",
      "f_id:  198r\n",
      "DP consensus dice: tensor([[0.9986, 0.5430]])\n",
      "STAPLE consensus dice: tensor([[0.9935, 0.2467]])\n",
      "\n",
      "f_id:  209r\n",
      "DP consensus dice: tensor([[0.9969, 0.5340]])\n",
      "STAPLE consensus dice: tensor([[0.9931, 0.3733]])\n",
      "\n",
      "f_id:  195r\n",
      "DP consensus dice: tensor([[0.9956, 0.4836]])\n",
      "STAPLE consensus dice: tensor([[0.9935, 0.4234]])\n",
      "\n",
      "f_id:  181r\n",
      "DP consensus dice: tensor([[0.9950, 0.7038]])\n",
      "STAPLE consensus dice: tensor([[0.9948, 0.7606]])\n",
      "\n",
      "f_id:  171r\n",
      "DP consensus dice: tensor([[0.9976, 0.7132]])\n",
      "STAPLE consensus dice: tensor([[0.9945, 0.5168]])\n",
      "\n",
      "f_id:  168r\n",
      "DP consensus dice: tensor([[0.9974, 0.7477]])\n",
      "STAPLE consensus dice: tensor([[0.9949, 0.6385]])\n",
      "\n",
      "f_id:  180r\n",
      "DP consensus dice: tensor([[0.9977, 0.7115]])\n",
      "STAPLE consensus dice: tensor([[0.9946, 0.5254]])\n",
      "\n",
      "f_id:  173r\n",
      "DP consensus dice: tensor([[0.9988, 0.8503]])\n",
      "STAPLE consensus dice: tensor([[0.9962, 0.6739]])\n",
      "\n",
      "f_id:  210r\n",
      "DP consensus dice: tensor([[0.9982, 0.7075]])\n",
      "STAPLE consensus dice: tensor([[0.9947, 0.4594]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cases = ['400_deeds', '1200_deeds', '1800_deeds', '400_convex_adam']\n",
    "current_case = cases[0]\n",
    "\n",
    "print(f\"Creating consensus for {current_case}\")\n",
    "\n",
    "if current_case == '400_deeds':\n",
    "    # Training with 400 labels (deeds)\n",
    "    network_scores = torch.load(\"/share/data_supergrover1/weihsbach/shared_data/important_data_artifacts/curriculum_deeplab/data/output/dashing-surf-1206_fold0_epx39/train_label_snapshot.pth\")\n",
    "\n",
    "elif current_case == '400_convex_adam':\n",
    "    # Training with 400 labels (convex adam)\n",
    "    network_scores = torch.load(\"/share/data_supergrover1/weihsbach/shared_data/important_data_artifacts/curriculum_deeplab/data/output/winter-frost-32_fold0_epx39/train_label_snapshot.pth\")\n",
    "\n",
    "elif current_case == '1200_deeds':\n",
    "    network_scores = torch.load(\"/share/data_supergrover1/weihsbach/shared_data/important_data_artifacts/curriculum_deeplab/data/output/classic-sunset-1245_fold0_epx39/train_label_snapshot.pth\")\n",
    "\n",
    "elif current_case == '1800_deeds':\n",
    "    network_scores = torch.load(\"/share/data_supergrover1/weihsbach/shared_data/important_data_artifacts/curriculum_deeplab/data/output/comic-sponge-1268_fold0_epx29/train_label_snapshot.pth\")\n",
    "\n",
    "data_paths = torch.load(\"/share/data_supergrover1/weihsbach/shared_data/important_data_artifacts/curriculum_deeplab/data/output/comic-sponge-1268_fold0_epx29/network_dataset_path_dict_train_1800.pth\")\n",
    "\n",
    "\n",
    "consensus_dicts = {}\n",
    "d_ids = network_scores['d_ids']\n",
    "\n",
    "print(\"Reading labels\")\n",
    "for _id in d_ids:\n",
    "    network_data_lookup_idx = d_ids.index(_id)\n",
    "    f_id = _id[:4]\n",
    "    m_id = _id[6:]\n",
    "    if f_id in consensus_dicts:\n",
    "        fixed_dict = consensus_dicts.get(f_id)\n",
    "    else:\n",
    "        fixed_dict = {}\n",
    "        #Only add expert label in first hit of fixed_dict\n",
    "        fixed_dict['expert_label'] = network_scores['labels'][network_data_lookup_idx]\n",
    "        fixed_dict['prediction'] = network_scores['train_predictions'][network_data_lookup_idx]\n",
    "        fixed_dict['image_path'] = data_paths['train_image_paths'][_id]\n",
    "\n",
    "    moving_dict = fixed_dict.get(m_id, {})\n",
    "    moving_dict['warped_label'] = network_scores['modified_labels'][network_data_lookup_idx]\n",
    "    moving_dict['data_parameter'] = network_scores['data_parameters'][network_data_lookup_idx]\n",
    "    \n",
    "    fixed_dict[m_id] = moving_dict\n",
    "    \n",
    "    consensus_dicts[f_id] = fixed_dict\n",
    "\n",
    "\n",
    "print(\"Getting consensus scores\")\n",
    "dp_consensus_dices = []\n",
    "staple_consensus_dices = []\n",
    "\n",
    "print(consensus_dicts.keys())\n",
    "for f_id, fixed_dict in tqdm(consensus_dicts.items()):\n",
    "    # print(len(fixed_dict))\n",
    "    lbls = []\n",
    "    lbls = [elem['warped_label'] for elem in fixed_dict.values() if isinstance(elem, dict)]\n",
    "    data_parameters = []\n",
    "    data_parameters = [elem['data_parameter'] for elem in fixed_dict.values() if isinstance(elem, dict)]\n",
    "    expert_label = fixed_dict['expert_label'].to_dense()\n",
    "    # lbls.append(fixed_dict['prediction'].to_dense().squeeze().to_sparse())\n",
    "    # data_parameters.append(max(data_parameters))\n",
    "    # data_parameters.append(0.)\n",
    "\n",
    "    dp_consensus = calc_dp_consensus(lbls, data_parameters)\n",
    "    staaple_consensus = calc_staple_consensus(lbls, data_parameters)\n",
    "    \n",
    "    # print()\n",
    "    # print(\"Expert label W sum\")\n",
    "    # plt.imshow(expert_label.float().mean((-1)))\n",
    "    # plt.show()\n",
    "    dp_dsc = dice3d(\n",
    "        torch.nn.functional.one_hot(dp_consensus.unsqueeze(0), 2),\n",
    "        torch.nn.functional.one_hot(expert_label.unsqueeze(0), 2),\n",
    "        one_hot_torch_style=True, nan_for_unlabeled_target=False\n",
    "    )\n",
    "    staple_dsc = dice3d(\n",
    "        torch.nn.functional.one_hot(staaple_consensus.unsqueeze(0), 2),\n",
    "        torch.nn.functional.one_hot(expert_label.unsqueeze(0), 2),\n",
    "        one_hot_torch_style=True, nan_for_unlabeled_target=False\n",
    "    )\n",
    "    print('f_id: ', f_id)\n",
    "    print(f\"DP consensus dice:\", dp_dsc)\n",
    "    print(f\"STAPLE consensus dice:\", staple_dsc)\n",
    "    print()\n",
    "    \n",
    "    fixed_dict['dp_consensus'] = dp_consensus.to_sparse()\n",
    "    fixed_dict['staple_consensus'] = staaple_consensus.to_sparse()\n",
    "    \n",
    "    fixed_dict['dp_consensus_oracle_dice'] = dp_dsc\n",
    "    fixed_dict['staple_consensus_oracle_dice'] = staple_dsc\n",
    "\n",
    "    consensus_dicts[f_id] = fixed_dict\n",
    "\n",
    "torch.save(consensus_dicts, f\"consensus_dict_{current_case}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from '/share/data_supergrover1/weihsbach/shared_data/important_data_artifacts/curriculum_deeplab/20220125_consensus/consensus_dict_400_deeds.pth'\n",
      "DP consensus mean dice: 0.654\n",
      "STAPLE consensus mean dice: 0.581\n",
      "\n",
      "Extracting data from '/share/data_supergrover1/weihsbach/shared_data/important_data_artifacts/curriculum_deeplab/20220323_consensus_convex_adam/consensus_dict_400_convex_adam.pth'\n",
      "DP consensus mean dice: 0.616\n",
      "STAPLE consensus mean dice: 0.568\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def extract_consensus_dices(consensus_path):\n",
    "    print(f\"Extracting data from '{consensus_path}'\")\n",
    "    consensus_dicts = torch.load(consensus_path)\n",
    "    dp_consensus_dices = []\n",
    "    staple_consensus_dices = []\n",
    "\n",
    "    for f_id, fixed_dict in consensus_dicts.items():\n",
    "        dp_consensus_dices.append(fixed_dict['dp_consensus_oracle_dice'])\n",
    "        staple_consensus_dices.append(fixed_dict['staple_consensus_oracle_dice']) \n",
    "\n",
    "    dp_tumour_dices = torch.cat(dp_consensus_dices)[:,1]\n",
    "    staple_tumour_dices = torch.cat(staple_consensus_dices)[:,1]\n",
    "\n",
    "    print(f\"DP consensus mean dice: {dp_tumour_dices.mean().item():.3f}\")\n",
    "    print(f\"STAPLE consensus mean dice: {staple_tumour_dices.mean().item():.3f}\")\n",
    "    print()\n",
    "    return dp_tumour_dices, staple_tumour_dices\n",
    "\n",
    "# Load consensus dices\n",
    "consensus_dicts_convex_adam_path = \"/share/data_supergrover1/weihsbach/shared_data/important_data_artifacts/curriculum_deeplab/20220323_consensus_convex_adam/consensus_dict_400_convex_adam.pth\"\n",
    "consensus_dicts_deeds_path = \"/share/data_supergrover1/weihsbach/shared_data/important_data_artifacts/curriculum_deeplab/20220125_consensus/consensus_dict_400_deeds.pth\"\n",
    "\n",
    "dp_consensus_dices_deeds, staple_consensus_dices_deeds = extract_consensus_dices(consensus_dicts_deeds_path)\n",
    "dp_consensus_dices_convex_adam, staple_consensus_dices_convex_adam = extract_consensus_dices(consensus_dicts_convex_adam_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 216x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "boxplot_data_deeds = [staple_consensus_dices_deeds.tolist(), dp_consensus_dices_deeds.tolist()]\n",
    "boxplot_data_convex_adam = [staple_consensus_dices_convex_adam.tolist(), dp_consensus_dices_convex_adam.tolist()]\n",
    "# df_deeds = pd.DataFrame(boxplot_data_deeds, index=['STAPLE consensus', 'DP consensus'])\n",
    "\n",
    "hues = {\n",
    "    'purple': (125/255, 84/255, 178/255),\n",
    "    'red': (218/255, 76/255, 76/255),\n",
    "    'yellow': (237/255, 183/255, 50/255),\n",
    "    'green': (135/255, 206/255, 191/255),\n",
    "    'gray': (161/255, 169/255, 173/255),\n",
    "    'darkgray': (80/255, 85/255, 90/255),\n",
    "\n",
    "}\n",
    "LINE_WIDTH = 1\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(3, 2.5))\n",
    "lineprops = dict(color=hues['darkgray'], linewidth=LINE_WIDTH)\n",
    "boxprops=dict(color=hues['darkgray'], linewidth=LINE_WIDTH)\n",
    "flierprops = dict(marker='o', markerfacecolor=hues['darkgray'], markersize=4,\n",
    "                  linestyle='none', markeredgecolor='none')\n",
    "# rectangular box plot\n",
    "bplot_deeds = ax.boxplot(boxplot_data_deeds,\n",
    "                    widths = 0.2,\n",
    "                    positions=[3-0.2, 4-0.2],\n",
    "                     vert=True,  # vertical box alignment\n",
    "                     patch_artist=True,  # fill with color\n",
    "                    #  labels=['DP', 'STAPLE'], \n",
    "                     showmeans=True,\n",
    "                     flierprops=flierprops, boxprops=boxprops,\n",
    "                     whiskerprops=lineprops, capprops=lineprops,\n",
    "                     meanline=True, medianprops=lineprops, meanprops=lineprops, \n",
    "                    #  showfliers=False\n",
    "                     )\n",
    "\n",
    "bplot_convex_adam = ax.boxplot(boxplot_data_convex_adam,\n",
    "                    widths = 0.2,\n",
    "                    positions=[3+0.2, 4+0.2],\n",
    "                     vert=True,  # vertical box alignment\n",
    "                     patch_artist=True,  # fill with color\n",
    "                    #  labels=['DP', 'STAPLE'], \n",
    "                     showmeans=True,\n",
    "                     flierprops=flierprops, boxprops=boxprops,\n",
    "                     whiskerprops=lineprops, capprops=lineprops,\n",
    "                     meanline=True, medianprops=lineprops, meanprops=lineprops, \n",
    "                    #  showfliers=False\n",
    "                     )\n",
    "\n",
    "plt.rcParams.update({'font.size': 8})\n",
    "ax.set_ylim([0.0,1.0])\n",
    "# ax.set_xlim([-.1,0.3])\n",
    "\n",
    "for box_patch, flier_patch, color in zip(bplot_deeds['boxes'], bplot_deeds['fliers'], [hues['yellow'], hues['yellow']]):\n",
    "     box_patch.set_facecolor(color)\n",
    "     flier_patch.set_markerfacecolor(color)\n",
    "     flier_patch.set_markeredgecolor(hues['darkgray'])\n",
    "\n",
    "for box_patch, flier_patch, color in zip(bplot_convex_adam['boxes'], bplot_convex_adam['fliers'], [hues['purple'], hues['purple']]):\n",
    "     box_patch.set_facecolor(color)\n",
    "     flier_patch.set_markerfacecolor(color)\n",
    "     flier_patch.set_markeredgecolor(hues['darkgray'])\n",
    "# ax.set_yticklabels([])\n",
    "# ax.tick_params(\n",
    "#     axis='y',          # changes apply to the x-axis\n",
    "#     which='both',      # both major and minor ticks are affected\n",
    "#     left=False,      # ticks along the bottom edge are off\n",
    "#     right=False,         # ticks along the top edge are off\n",
    "#     labelbottom=False) # labels along the bottom edge are off\n",
    "ax.xaxis.set_tick_params(width=LINE_WIDTH)\n",
    "ax.yaxis.set_tick_params(width=LINE_WIDTH, color=hues['darkgray'])\n",
    "[x.set_linewidth(LINE_WIDTH) for x in ax.spines.values()]\n",
    "[x.set_color(hues['darkgray']) for x in ax.spines.values()]\n",
    "ax.tick_params(axis='x', colors=hues['darkgray'])\n",
    "plt.bar([0-0.2, 1-0.2, 2-0.2, 3-0.2, 4-0.2, 5-0.2], [0.48,0.56928, -1, 0.636, .678, .844], color=hues['yellow'], width=0.4)\n",
    "plt.bar([0+0.2, 1+0.2, 2+0.2, 3+0.2, 4+0.2, 5+0.2], [-1, -1, -1, -1, -1, -1], color=hues['purple'], width=0.4)\n",
    "# plt.bar([0,1,2,3,4], [0.48,0.56928,0.636,.678,.844], color=hues['yellow'])\n",
    "ax.set_xticks([0,1,2,3,4,5])\n",
    "ax.set_xticklabels(['RND', 'ALL', 'INS', 'STAPLE', 'DP', 'ORACLE'])\n",
    "# plt.title('deeds registration', color=hues['darkgray'])\n",
    "plt.savefig(\"box2.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "06ba18e7235aac9e9578e5cb0339dda8530a2db7f5b95196862af1240ab4b857"
  },
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
