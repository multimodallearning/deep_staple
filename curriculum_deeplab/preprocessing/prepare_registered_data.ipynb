{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registered data from CrossModa challenge by Mattias\n",
    "# crossmoda_\"target\" -> crossmoda_\"source\"\n",
    "#                 T2 -> T1\n",
    "#             moving -> fixed\n",
    "\n",
    "# Data originally stored in\n",
    "# \"/share/data_supergrover1/heinrich/crossmoda_convex/\"\n",
    "# 900 registrations (1F<-30M)x30\n",
    "\n",
    "# \"/share/data_supergrover1/heinrich/crossmoda_convex/\"\n",
    "# 900 registrations (1F<-30M)x30\n",
    "\n",
    "# load with:\n",
    "# contains nested dicts with dict[fixed_id][moving_id] with sparse label tensors.\n",
    "# Use .to_dense() to unpack\n",
    "\n",
    "# Script to reproduce\n",
    "\n",
    "```python\n",
    "load_set = \"deeds\"\n",
    "\n",
    "if load_set == \"convex\":\n",
    "    data_path = \"/share/data_supergrover1/weihsbach/shared_data/tmp/tmp_convex/\"\n",
    "    convex_path =  \"/share/data_supergrover1/heinrich/crossmoda_convex/\"\n",
    "    registered_files = glob.glob(data_path+\"*.nii.gz\")\n",
    "    # registered_files = [\"/share/data_supergrover1/weihsbach/shared_data/tmp/tmp_convex/Fcrossmoda108_M100.nii.gz\"]\n",
    "elif load_set == \"deeds\":\n",
    "    data_path = \"/share/data_supergrover1/heinrich/crossmoda_deeds/\"\n",
    "    convex_path =  \"/share/data_supergrover1/heinrich/crossmoda_convex/\"\n",
    "    registered_files = glob.glob(data_path+\"*seg.nii.gz\")\n",
    "\n",
    "dice_files_right = torch.load(convex_path+\"dice_files_right.pth\")\n",
    "dice_files_left = torch.load(convex_path+\"dice_files_left.pth\")\n",
    "\n",
    "orig_path = \"/share/data_supergrover1/weihsbach/shared_data/tmp/CrossMoDa/L4_fine_localized_crop/\"\n",
    "\n",
    "# print(registered_files)\n",
    "dice_files_right = torch.load(convex_path+\"dice_files_right.pth\")\n",
    "dice_files_left = torch.load(convex_path+\"dice_files_left.pth\")\n",
    "\n",
    "fixed_files_right = dice_files_right['target_tumour_right']\n",
    "fixed_files_right = set([elem[0] for elem in fixed_files_right])\n",
    "fixed_files_left = dice_files_left['target_tumour_left']\n",
    "fixed_files_left = set([elem[0] for elem in fixed_files_left])\n",
    "\n",
    "moving_files_right = dice_files_right['source_tumour_right']\n",
    "moving_files_right = set([elem[0] for elem in moving_files_right])\n",
    "moving_files_left = dice_files_left['source_tumour_left']\n",
    "moving_files_left = set([elem[0] for elem in moving_files_left])\n",
    "\n",
    "all_fixed_files = sorted(list(fixed_files_left.union(fixed_files_right)))\n",
    "all_moving_files = sorted(list(moving_files_left.union(moving_files_right)))\n",
    "\n",
    "\n",
    "def filter_ids(_file):\n",
    "    num_id, lr_id = re.findall(r\"(\\d{1,3})_Label_([lr])\", _file)[0]\n",
    "    _id = f'{int(num_id):03d}{lr_id}'\n",
    "    numeric_short = int(_id[:3])\n",
    "    return (_id, numeric_short, _file)\n",
    "\n",
    "fixed_ids = [filter_ids(f_name) for f_name in all_fixed_files]\n",
    "moving_ids = [filter_ids(f_name) for f_name in all_moving_files]\n",
    "\n",
    "data_dict = {}\n",
    "\n",
    "used_fids_short = []\n",
    "used_mids_short = []\n",
    "\n",
    "def get_convex_fixed_moving_num(_file):\n",
    "    fixed_num, moving_num = re.findall(r\"(\\d{1,3})r_M(\\d{1,3})\", _file)[0]\n",
    "    fixed_num, moving_num = int(fixed_num), int(moving_num)\n",
    "    return fixed_num, moving_num\n",
    "\n",
    "def get_deeds_fixed_moving_num(_file):\n",
    "    fixed_num, moving_num = re.findall(r\"(\\d{1,3})_L_M(\\d{1,3})\", _file)[0]\n",
    "    fixed_num, moving_num = int(fixed_num), int(moving_num)\n",
    "    return fixed_num, moving_num\n",
    "\n",
    "for gz_file in registered_files:\n",
    "    if load_set == \"convex\":\n",
    "        fixed_num, moving_num = get_convex_fixed_moving_num(gz_file)\n",
    "    elif load_set == \"deeds\":\n",
    "        fixed_num, moving_num = get_deeds_fixed_moving_num(gz_file)\n",
    "    used_fids_short.append(fixed_num)\n",
    "    used_mids_short.append(moving_num)\n",
    "\n",
    "used_fids_short = list(set(used_fids_short))\n",
    "used_mids_short = list(set(used_mids_short))\n",
    "\n",
    "fixed_ids = list(filter(lambda elem: elem[1] in used_fids_short, fixed_ids))\n",
    "moving_ids = list(filter(lambda elem: elem[1] in used_mids_short, moving_ids))\n",
    "\n",
    "print(\"fixed_ids\", fixed_ids)\n",
    "print(\"moving_ids\", moving_ids)\n",
    "\n",
    "orig_label_dict = {}\n",
    "\n",
    "for _id, _, _file in fixed_ids:\n",
    "    file_path = orig_path + \"__omitted_labels_target_training__/\" + _file\n",
    "    file_path = file_path.replace(\"Label_l\", \"hrT2_l_Label\")\n",
    "    file_path = file_path.replace(\"Label_r\", \"hrT2_r_Label\")\n",
    "    if os.path.isfile(file_path):\n",
    "        orig_label_dict[_id] = torch.tensor(nib.load(file_path).get_fdata())\n",
    "\n",
    "warped_label_dict = {}\n",
    "for gz_file in registered_files:\n",
    "    if load_set == \"convex\":\n",
    "        fixed_num, moving_num = get_convex_fixed_moving_num(gz_file)\n",
    "        # gz_file = data_path + f\"crossmoda_{fixed_num}_L{moving_num}.nii.gz\"\n",
    "    elif load_set == \"deeds\":\n",
    "        fixed_num, moving_num = get_deeds_fixed_moving_num(gz_file)\n",
    "\n",
    "    warped_label = torch.tensor(nib.load(gz_file).get_fdata()).cuda()\n",
    "\n",
    "    fixed_id = list(filter(lambda elem: elem[1] == fixed_num, fixed_ids))\n",
    "    if not fixed_id:\n",
    "        continue\n",
    "    else:\n",
    "        fixed_id = fixed_id[0][0]\n",
    "    moving_id = list(filter(lambda elem: elem[1] == moving_num, moving_ids))\n",
    "    if not moving_id:\n",
    "        continue\n",
    "    else:\n",
    "        moving_id = moving_id[0][0]\n",
    "\n",
    "    dct = warped_label_dict.get(fixed_id, {})\n",
    "    dct[moving_id] = warped_label.to_sparse()\n",
    "    warped_label_dict[fixed_id] = dct\n",
    "\n",
    "print(len(orig_label_dict))\n",
    "\n",
    "for idx, gz_file in enumerate(registered_files):\n",
    "    if load_set == \"convex\":\n",
    "        fixed_num, moving_num = get_convex_fixed_moving_num(gz_file)\n",
    "    elif load_set == \"deeds\":\n",
    "        fixed_num, moving_num = get_deeds_fixed_moving_num(gz_file)\n",
    "\n",
    "    fixed_res = list(filter(lambda elem: elem[1] == fixed_num, fixed_ids))\n",
    "    if not fixed_res:\n",
    "        continue\n",
    "    else:\n",
    "        fixed_id, _, fixed_file = fixed_res[0]\n",
    "\n",
    "    moving_res = list(filter(lambda elem: elem[1] == moving_num, moving_ids))\n",
    "    if not moving_res:\n",
    "        continue\n",
    "    else:\n",
    "        moving_id, _, moving_file = moving_res[0]\n",
    "    dct = data_dict.get(fixed_id, {})\n",
    "\n",
    "    # orig_label = orig_label_dict[moving_id].cuda() # TODO\n",
    "    orig_label = orig_label_dict[fixed_id].cuda()\n",
    "    warped_label = warped_label_dict[fixed_id][moving_id].to_dense()\n",
    "\n",
    "    dice = dice3d(F.one_hot(orig_label.long(), 3).unsqueeze(0),\n",
    "          F.one_hot(warped_label.long(), 3).unsqueeze(0), one_hot_torch_style=True)\n",
    "\n",
    "    dct[moving_id] = {\n",
    "        'warped_label': warped_label.to_sparse(),\n",
    "        'dice': dice\n",
    "    }\n",
    "    data_dict[fixed_id] = dct\n",
    "\n",
    "    if idx % 60 == 0:\n",
    "    # if len(orig_label.unique()) != len(warped_label.unique()) or len(orig_label.unique()) < 2:\n",
    "        print(idx)\n",
    "        print(orig_label.unique())\n",
    "        print(warped_label.unique())\n",
    "        print(\"Registred file: \", gz_file)\n",
    "        print(\"Fixed file: \", fixed_file)\n",
    "        print(\"Moving file: \", moving_file)\n",
    "        print(f\"fixed: {fixed_num}, moving: {moving_num}\")\n",
    "        print(f\"fixed: {fixed_id}, moving: {moving_id}\")\n",
    "        print(dice)\n",
    "        print()\n",
    "\n",
    "torch.save(data_dict, THIS_SCRIPT_DIR+f\"/data/crossmoda_{load_set}_registered.pth\")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
