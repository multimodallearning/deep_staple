{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7502ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage.interpolation import map_coordinates, zoom\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import struct\n",
    "import scipy.ndimage\n",
    "from scipy.ndimage.interpolation import zoom as zoom\n",
    "from scipy.ndimage.interpolation import map_coordinates\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from meidic_vtach_utils.run_on_recommended_cuda import get_cuda_environ_vars as get_vars\n",
    "os.environ.update(get_vars(select=\"* -4\"))\n",
    "print(torch.__version__)\n",
    "import sys\n",
    "import time\n",
    "from scipy.ndimage import distance_transform_edt as edt\n",
    "\n",
    "A = torch.ones(64,64).cuda()\n",
    "A.requires_grad = True\n",
    "A.sum().backward()\n",
    "sys.path.append('/share/data_supergrover1/heinrich/voxelmorph/pytorch/')\n",
    "import losses\n",
    "print(losses.mind_loss)\n",
    "\n",
    "def gpu_usage():\n",
    "    print('gpu usage (current/max): {:.2f} / {:.2f} GB'.format(torch.cuda.memory_allocated()*1e-9, torch.cuda.max_memory_allocated()*1e-9))\n",
    "\n",
    "    \n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.ndimage.interpolation import zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c54686",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_LEFT = False\n",
    "valid_t1 = []\n",
    "folder_t1 = '/share/data_supergrover1/hansen/temp/crossMoDa/preprocessed_new/resampled/localised_crop/source_training/'\n",
    "files = sorted(os.listdir(folder_t1))\n",
    "print(len(files))\n",
    "count = 0\n",
    "img3d = torch.empty(0,128,128,128)#96,96)\n",
    "seg3d = torch.empty(0,128,128,128).long()#96,96).long()\n",
    "seg_all = torch.zeros(2,192)\n",
    "#slices = torch.zeros(2,96)\n",
    "for i,f in enumerate(files):\n",
    "    if(i%20==19):\n",
    "        print(i,'/',len(files))\n",
    "    if('128' in f):\n",
    "        continue\n",
    "    if LOAD_LEFT:\n",
    "        checkstr = 'Label_l'\n",
    "        filestr = '_ceT1_l.nii.gz'\n",
    "    else:\n",
    "        checkstr = 'Label_r'\n",
    "        filestr = '_ceT1_r.nii.gz'\n",
    "\n",
    "    if(checkstr in f):\n",
    "        #35:65\n",
    "        fsplit = f.split('_')\n",
    "        f1 = 'crossmoda_'+fsplit[1]+filestr\n",
    "        seg = torch.from_numpy(nib.load(folder_t1+f).get_fdata()).long().contiguous()\n",
    "        #print(seg.shape)\n",
    "        if((seg==1).sum()==0):\n",
    "            print(i,'no tumour')\n",
    "            continue\n",
    "        if(len(seg.unique())!=3):\n",
    "            continue\n",
    "        if(seg.shape[0]==0):\n",
    "            continue\n",
    "        valid_t1.append(f1)\n",
    "        seg3d = torch.cat((seg3d,seg.unsqueeze(0)),0)\n",
    "        img = torch.from_numpy(nib.load(folder_t1+f1).get_fdata()).float().contiguous()\n",
    "        img3d = torch.cat((img3d,img.unsqueeze(0)),0)\n",
    "\n",
    "\n",
    "\n",
    "print('valid len',len(valid_t1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0a0049",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(valid_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4a255c",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_t2 = []\n",
    "folder_t2 = '/share/data_supergrover1/hansen/temp/crossMoDa/preprocessed_new/resampled/localised_crop/target_training/'\n",
    "\n",
    "files = sorted(os.listdir(folder_t2))\n",
    "print(len(files))\n",
    "count = 0\n",
    "img3d_t2 = torch.empty(0,128,128,128)#96,96)\n",
    "seg3d_t2 = torch.empty(0,128,128,128).long()#96,96).long()\n",
    "seg_all = torch.zeros(2,192)\n",
    "#slices = torch.zeros(2,96)\n",
    "for i,f in enumerate(files):\n",
    "    if(i%20==19):\n",
    "        print(i,'/',len(files))\n",
    "    if('128' in f):\n",
    "        continue\n",
    "    \n",
    "    if LOAD_LEFT:\n",
    "        checkstr = 'Label_l'\n",
    "        filestr = '_hrT2_l.nii.gz'\n",
    "    else:\n",
    "        checkstr = 'Label_r'\n",
    "        filestr = '_hrT2_r.nii.gz'\n",
    "\n",
    "    if(checkstr in f):\n",
    "        #35:65\n",
    "        fsplit = f.split('_')\n",
    "        f1 = 'crossmoda_'+fsplit[1]+filestr\n",
    "        seg = torch.from_numpy(nib.load(folder_t2+f).get_fdata()).long().contiguous()\n",
    "        #print(seg.shape)\n",
    "        if((seg==1).sum()==0):\n",
    "            print(i,'no tumour')\n",
    "            continue\n",
    "        if(len(seg.unique())!=3):\n",
    "            continue\n",
    "        if(seg.shape[0]==0):\n",
    "            continue\n",
    "        valid_t2.append(f1)\n",
    "        seg3d_t2 = torch.cat((seg3d_t2,seg.unsqueeze(0)),0)\n",
    "        img = torch.from_numpy(nib.load(folder_t2+f1).get_fdata()).float().contiguous()\n",
    "        img3d_t2 = torch.cat((img3d_t2,img.unsqueeze(0)),0)\n",
    "\n",
    "\n",
    "\n",
    "print('valid len',len(valid_t2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2410ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation layer: dense discretised displacements to compute SSD cost volume with box-filter\n",
    "def correlate(mind_fix,mind_mov,disp_hw,grid_sp,shape):\n",
    "    H = int(shape[0]); W = int(shape[1]); D = int(shape[2]);\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    t0 = time.time()\n",
    "    with torch.no_grad():\n",
    "        mind_unfold = F.unfold(F.pad(mind_mov,(disp_hw,disp_hw,disp_hw,disp_hw,disp_hw,disp_hw)).squeeze(0),disp_hw*2+1)\n",
    "        mind_unfold = mind_unfold.view(12,-1,(disp_hw*2+1)**2,W//grid_sp,D//grid_sp)\n",
    "        \n",
    "\n",
    "    ssd = torch.zeros((disp_hw*2+1)**3,H//grid_sp,W//grid_sp,D//grid_sp,dtype=mind_fix.dtype, device=mind_fix.device)#.cuda().half()\n",
    "    ssd_argmin = torch.zeros(H//grid_sp,W//grid_sp,D//grid_sp).long()\n",
    "    with torch.no_grad():\n",
    "        for i in range(disp_hw*2+1):\n",
    "            mind_sum = (mind_fix.permute(1,2,0,3,4)-mind_unfold[:,i:i+H//grid_sp]).pow(2).sum(0,keepdim=True)\n",
    "            #5,stride=1,padding=2\n",
    "            #3,stride=1,padding=1\n",
    "            ssd[i::(disp_hw*2+1)] = F.avg_pool3d(F.avg_pool3d(mind_sum.transpose(2,1),3,stride=1,padding=1),3,stride=1,padding=1).squeeze(1)\n",
    "        ssd = ssd.view(disp_hw*2+1,disp_hw*2+1,disp_hw*2+1,H//grid_sp,W//grid_sp,D//grid_sp).transpose(1,0).reshape((disp_hw*2+1)**3,H//grid_sp,W//grid_sp,D//grid_sp)\n",
    "        ssd_argmin = torch.argmin(ssd,0)#\n",
    "        #ssd = F.softmax(-ssd*1000,0)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    t1 = time.time()\n",
    "    #print(t1-t0,'sec (ssd)')\n",
    "    #gpu_usage()\n",
    "    return ssd,ssd_argmin\n",
    "\n",
    "#solve two coupled convex optimisation problems for efficient global regularisation\n",
    "def coupled_convex(ssd,ssd_argmin,disp_mesh_t,grid_sp,shape):\n",
    "    H = int(shape[0]); W = int(shape[1]); D = int(shape[2]);\n",
    "\n",
    "    disp_soft = F.avg_pool3d(disp_mesh_t.view(3,-1)[:,ssd_argmin.view(-1)].reshape(1,3,H//grid_sp,W//grid_sp,D//grid_sp),3,padding=1,stride=1)\n",
    "\n",
    "    coeffs = torch.tensor([0.003,0.01,0.03,0.1,0.3,1])\n",
    "    for j in range(6):\n",
    "        ssd_coupled_argmin = torch.zeros_like(ssd_argmin)\n",
    "        with torch.no_grad():\n",
    "            for i in range(H//grid_sp):\n",
    "\n",
    "                coupled = ssd[:,i,:,:]+coeffs[j]*(disp_mesh_t-disp_soft[:,:,i].view(3,1,-1)).pow(2).sum(0).view(-1,W//grid_sp,D//grid_sp)\n",
    "                ssd_coupled_argmin[i] = torch.argmin(coupled,0)\n",
    "            #print(coupled.shape)\n",
    "\n",
    "        disp_soft = F.avg_pool3d(disp_mesh_t.view(3,-1)[:,ssd_coupled_argmin.view(-1)].reshape(1,3,H//grid_sp,W//grid_sp,D//grid_sp),3,padding=1,stride=1)\n",
    "\n",
    "    return disp_soft\n",
    "\n",
    "#enforce inverse consistency of forward and backward transform\n",
    "def inverse_consistency(disp_field1s,disp_field2s,iter=20):\n",
    "    #factor = 1\n",
    "    B,C,H,W,D = disp_field1s.size()\n",
    "    #make inverse consistent\n",
    "    with torch.no_grad():\n",
    "        disp_field1i = disp_field1s.clone()\n",
    "        disp_field2i = disp_field2s.clone()\n",
    "\n",
    "        identity = F.affine_grid(torch.eye(3,4).unsqueeze(0),(1,1,H,W,D)).permute(0,4,1,2,3).to(disp_field1s.device).to(disp_field1s.dtype)\n",
    "        for i in range(iter):\n",
    "            disp_field1s = disp_field1i.clone()\n",
    "            disp_field2s = disp_field2i.clone()\n",
    "\n",
    "            disp_field1i = 0.5*(disp_field1s-F.grid_sample(disp_field2s,(identity+disp_field1s).permute(0,2,3,4,1)))\n",
    "            disp_field2i = 0.5*(disp_field2s-F.grid_sample(disp_field1s,(identity+disp_field2s).permute(0,2,3,4,1)))\n",
    "\n",
    "    return disp_field1i,disp_field2i\n",
    "\n",
    "def combineDeformation3d(disp_1st,disp_2nd,identity):\n",
    "    disp_composition = disp_2nd + F.grid_sample(disp_1st,disp_2nd.permute(0,2,3,4,1)+identity)\n",
    "    return disp_composition\n",
    "\n",
    "def kpts_pt(kpts_world, shape):\n",
    "    device = kpts_world.device\n",
    "    H, W, D = shape\n",
    "    return (kpts_world.flip(-1) / (torch.tensor([D, W, H]).to(device) - 1)) * 2 - 1\n",
    "\n",
    "def kpts_world(kpts_pt, shape):\n",
    "    device = kpts_pt.device\n",
    "    H, W, D = shape\n",
    "    return ((kpts_pt.flip(-1) + 1) / 2) * (torch.tensor([H, W, D]).to(device) - 1)\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TPS:\n",
    "    @staticmethod\n",
    "    def fit(c, f, lambd=0.):\n",
    "        device = c.device\n",
    "        \n",
    "        n = c.shape[0]\n",
    "        f_dim = f.shape[1]\n",
    "\n",
    "        U = TPS.u(TPS.d(c, c))\n",
    "        K = U + torch.eye(n, device=device) * lambd\n",
    "\n",
    "        P = torch.ones((n, 4), device=device)\n",
    "        P[:, 1:] = c\n",
    "\n",
    "        v = torch.zeros((n+4, f_dim), device=device)\n",
    "        v[:n, :] = f\n",
    "\n",
    "        A = torch.zeros((n+4, n+4), device=device)\n",
    "        A[:n, :n] = K\n",
    "        A[:n, -4:] = P\n",
    "        A[-4:, :n] = P.t()\n",
    "\n",
    "        theta = torch.solve(v, A)[0]\n",
    "        return theta\n",
    "        \n",
    "    @staticmethod\n",
    "    def d(a, b):\n",
    "        ra = (a**2).sum(dim=1).view(-1, 1)\n",
    "        rb = (b**2).sum(dim=1).view(1, -1)\n",
    "        dist = ra + rb - 2.0 * torch.mm(a, b.permute(1, 0))\n",
    "        dist.clamp_(0.0, float('inf'))\n",
    "        return torch.sqrt(dist)\n",
    "\n",
    "    @staticmethod\n",
    "    def u(r):\n",
    "        return (r**2) * torch.log(r + 1e-6)\n",
    "\n",
    "    @staticmethod\n",
    "    def z(x, c, theta):\n",
    "        U = TPS.u(TPS.d(x, c))\n",
    "        w, a = theta[:-4], theta[-4:].unsqueeze(2)\n",
    "        b = torch.matmul(U, w)\n",
    "        return (a[0] + a[1] * x[:, 0] + a[2] * x[:, 1] + a[3] * x[:, 2] + b.t()).t()\n",
    "    \n",
    "def thin_plate_dense(x1, y1, shape, step, lambd=.0, unroll_step_size=2**12):\n",
    "    device = x1.device\n",
    "    D, H, W = shape\n",
    "    D1, H1, W1 = D//step, H//step, W//step\n",
    "    \n",
    "    x2 = F.affine_grid(torch.eye(3, 4, device=device).unsqueeze(0), (1, 1, D1, H1, W1), align_corners=True).view(-1, 3)\n",
    "    tps = TPS()\n",
    "    theta = tps.fit(x1[0], y1[0], lambd)\n",
    "    \n",
    "    y2 = torch.zeros((1, D1 * H1 * W1, 3), device=device)\n",
    "    N = D1*H1*W1\n",
    "    n = math.ceil(N/unroll_step_size)\n",
    "    for j in range(n):\n",
    "        j1 = j * unroll_step_size\n",
    "        j2 = min((j + 1) * unroll_step_size, N)\n",
    "        y2[0, j1:j2, :] = tps.z(x2[j1:j2], x1[0], theta)\n",
    "        \n",
    "    y2 = y2.view(1, D1, H1, W1, 3).permute(0, 4, 1, 2, 3)\n",
    "    y2 = F.interpolate(y2, (D, H, W), mode='trilinear', align_corners=True).permute(0, 2, 3, 4, 1)\n",
    "    \n",
    "    return y2\n",
    "\n",
    "\n",
    "H=W=D=64\n",
    "\n",
    "#print(img_fixed.shape)\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "def dice_coeff(outputs, labels, max_label):\n",
    "    dice = torch.FloatTensor(max_label-1).fill_(0)\n",
    "    for label_num in range(1, max_label):\n",
    "        iflat = (outputs==label_num).view(-1).float()\n",
    "        tflat = (labels==label_num).view(-1).float()\n",
    "        intersection = torch.mean(iflat * tflat)\n",
    "        dice[label_num-1] = (2. * intersection) / (1e-8 + torch.mean(iflat) + torch.mean(tflat))\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79acd039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convexAdam(img_fixed,img_moving):\n",
    "    grid_sp = 4\n",
    "    disp_hw = 8\n",
    "\n",
    "\n",
    "\n",
    "    #compute MIND descriptors and downsample (using average pooling)\n",
    "    with torch.no_grad():\n",
    "        mindssc_fix = losses.MINDSSC(img_fixed.unsqueeze(0).unsqueeze(0).cuda(),1,2).half()#*fixed_mask.cuda().half()#.cpu()\n",
    "        mindssc_mov = losses.MINDSSC(img_moving.unsqueeze(0).unsqueeze(0).cuda(),1,2).half()#*moving_mask.cuda().half()#.cpu()\n",
    "\n",
    "        mind_fix = F.avg_pool3d(mindssc_fix,grid_sp,stride=grid_sp)\n",
    "        mind_mov = F.avg_pool3d(mindssc_mov,grid_sp,stride=grid_sp)\n",
    "\n",
    "\n",
    "    ssd,ssd_argmin = correlate(mind_fix,mind_mov,disp_hw,grid_sp,(H,W,D))\n",
    "    disp_mesh_t = F.affine_grid(disp_hw*torch.eye(3,4).cuda().half().unsqueeze(0),(1,1,disp_hw*2+1,disp_hw*2+1,disp_hw*2+1),align_corners=True).permute(0,4,1,2,3).reshape(3,-1,1)\n",
    "    disp_soft = coupled_convex(ssd,ssd_argmin,disp_mesh_t,grid_sp,(H,W,D))\n",
    "    scale = torch.tensor([H//grid_sp-1,W//grid_sp-1,D//grid_sp-1]).view(1,3,1,1,1).cuda().half()/2\n",
    "    ssd_,ssd_argmin_ = correlate(mind_mov,mind_fix,disp_hw,grid_sp,(H,W,D))\n",
    "    disp_soft_ = coupled_convex(ssd_,ssd_argmin_,disp_mesh_t,grid_sp,(H,W,D))\n",
    "    disp_ice,_ = inverse_consistency((disp_soft/scale).flip(1),(disp_soft_/scale).flip(1),iter=15)\n",
    "\n",
    "    disp_hr = F.interpolate(disp_ice.flip(1)*scale*grid_sp,size=(H,W,D),mode='trilinear',align_corners=False)\n",
    "\n",
    "\n",
    "    grid_sp = 3\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        patch_mind_fix = F.avg_pool3d(mindssc_fix,grid_sp,stride=grid_sp)\n",
    "        patch_mind_mov = F.avg_pool3d(mindssc_mov,grid_sp,stride=grid_sp)\n",
    "\n",
    "\n",
    "    #create optimisable displacement grid\n",
    "    disp_lr = F.interpolate(disp_hr,size=(H//grid_sp,W//grid_sp,D//grid_sp),mode='trilinear',align_corners=False)\n",
    "\n",
    "\n",
    "    net = nn.Sequential(nn.Conv3d(3,1,(H//grid_sp,W//grid_sp,D//grid_sp),bias=False))\n",
    "    net[0].weight.data[:] = disp_lr.float().cpu().data/grid_sp\n",
    "    net.cuda()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=1)\n",
    "    #torch.cuda.synchronize()\n",
    "    #t0 = time.time()\n",
    "    grid0 = F.affine_grid(torch.eye(3,4).unsqueeze(0).cuda(),(1,1,H//grid_sp,W//grid_sp,D//grid_sp),align_corners=False)\n",
    "\n",
    "    #run Adam optimisation with diffusion regularisation and B-spline smoothing\n",
    "    lambda_weight = .6# with tps: .5, without:0.7\n",
    "    for iter in range(40):#80\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        disp_sample = F.avg_pool3d(F.avg_pool3d(F.avg_pool3d(net[0].weight,3,stride=1,padding=1),3,stride=1,padding=1),3,stride=1,padding=1).permute(0,2,3,4,1)\n",
    "        reg_loss = lambda_weight*((disp_sample[0,:,1:,:]-disp_sample[0,:,:-1,:])**2).mean()+\\\n",
    "        lambda_weight*((disp_sample[0,1:,:,:]-disp_sample[0,:-1,:,:])**2).mean()+\\\n",
    "        lambda_weight*((disp_sample[0,:,:,1:]-disp_sample[0,:,:,:-1])**2).mean()\n",
    "\n",
    "        #grid_disp = grid0.view(-1,3).cuda().float()+((disp_sample.view(-1,3))/torch.tensor([63/2,63/2,68/2]).unsqueeze(0).cuda()).flip(1)\n",
    "\n",
    "        scale = torch.tensor([(H//grid_sp-1)/2,(W//grid_sp-1)/2,(D//grid_sp-1)/2]).cuda().unsqueeze(0)\n",
    "        grid_disp = grid0.view(-1,3).cuda().float()+((disp_sample.view(-1,3))/scale).flip(1).float()\n",
    "\n",
    "        patch_mov_sampled = F.grid_sample(patch_mind_mov.float(),grid_disp.view(1,H//grid_sp,W//grid_sp,D//grid_sp,3).cuda(),align_corners=False,mode='bilinear')#,padding_mode='border')\n",
    "        #patch_mov_sampled_sq = F.grid_sample(patch_mind_mov.pow(2).float(),grid_disp.view(1,H//grid_sp,W//grid_sp,D//grid_sp,3).cuda(),align_corners=True,mode='bilinear')\n",
    "        #sampled_cost = (patch_mov_sampled_sq-2*patch_mov_sampled*patch_mind_fix+patch_mind_fix.pow(2)).mean(1)*12\n",
    "\n",
    "        sampled_cost = (patch_mov_sampled-patch_mind_fix).pow(2).mean(1)*12\n",
    "        #sampled_cost = F.grid_sample(ssd2.view(-1,1,17,17,17).float(),disp_sample.view(-1,1,1,1,3)/disp_hw,align_corners=True,padding_mode='border')\n",
    "        loss = sampled_cost.mean()\n",
    "        (loss+reg_loss).backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    fitted_grid = disp_sample.permute(0,4,1,2,3).detach()\n",
    "    #fitted_smooth = F.avg_pool3d(F.avg_pool3d(F.avg_pool3d(fitted_grid,3,padding=1,stride=1),3,padding=1,stride=1),3,padding=1,stride=1)\n",
    "    disp_hr = F.interpolate(fitted_grid*grid_sp,size=(H,W,D),mode='trilinear',align_corners=False)\n",
    "\n",
    "\n",
    "    disp_smooth = F.avg_pool3d(F.avg_pool3d(F.avg_pool3d(disp_hr,3,padding=1,stride=1),3,padding=1,stride=1),3,padding=1,stride=1)\n",
    "\n",
    "    disp = disp_smooth.cuda().float().permute(0,2,3,4,1)/torch.tensor([H-1,W-1,D-1]).cuda().view(1,1,1,1,3)*2\n",
    "    disp = disp.flip(4)\n",
    "    \n",
    "    return disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c9e252",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img3d.shape,img3d_t2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3c8957",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((seg3d==2).sum(0).sum(-1)[8:-56,48:-16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436933d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((seg3d==1).sum(0).sum(-1)[56:-8,48:-16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ae386c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((seg3d==1).sum(0).sum(-2)[8:-56,40:-24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd6a4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_lenn = len(valid_t2)\n",
    "_N = 4\n",
    "\n",
    "best_all = torch.zeros_like(img3d)\n",
    "best_n_all = torch.zeros_like(img3d).repeat(_N,1,1,1)\n",
    "combined_all = torch.zeros_like(img3d)\n",
    "multiple_all = torch.zeros_like(img3d).repeat(moving_lenn,1,1,1)\n",
    "\n",
    "fixed_len = img3d.shape[0]\n",
    "\n",
    "import time\n",
    "t0 = time.time()\n",
    "for fix in range(fixed_len):\n",
    "    print(fix,time.time()-t0,'sec (total)')\n",
    "    before = torch.zeros(moving_lenn,2)\n",
    "    after = torch.zeros(moving_lenn,2)\n",
    "    combined = torch.zeros(3,64,64,64)\n",
    "    mov_all = torch.zeros(moving_lenn,128,128,128)\n",
    "\n",
    "    for i in range(moving_lenn):\n",
    "        disp = convexAdam(img3d[fix,56:-8,48:-16,40:-24],img3d_t2[i,56:-8,48:-16,40:-24])\n",
    "        warped_one_hot = F.grid_sample(F.one_hot(seg3d_t2[i,56:-8,48:-16,40:-24].long(),3).permute(3,0,1,2).float().cuda().view(1,3,H,W,D),F.affine_grid(torch.eye(3,4).cuda().unsqueeze(0),(1,1,H,W,D))+disp.cuda(),mode='bilinear')\n",
    "        combined += warped_one_hot.squeeze().cpu()\n",
    "        warped_seg = warped_one_hot.argmax(1).squeeze()\n",
    "        mov_all[i,56:-8,48:-16,40:-24] = warped_seg\n",
    "        multiple_all[fix*i] = mov_all[i]\n",
    "        before[i] = (dice_coeff(seg3d[fix,56:-8,48:-16,40:-24],seg3d_t2[i,56:-8,48:-16,40:-24],3))\n",
    "        after[i] = (dice_coeff(seg3d[fix,56:-8,48:-16,40:-24],warped_seg.squeeze().cpu(),3))\n",
    "    combined = F.avg_pool3d(F.avg_pool3d(F.avg_pool3d(combined.unsqueeze(0),3,stride=1,padding=1),3,stride=1,padding=1),3,stride=1,padding=1).squeeze()\n",
    "    combined[0] *= 0.66\n",
    "    print('before', before.mean(0), before.max(0)[0])\n",
    "    print('after', after.mean(0), after.max(0)[0], after.min(0)[0],)\n",
    "    print('combined', dice_coeff(seg3d[fix,56:-8,48:-16,40:-24], (combined[:,:,:,:].argmax(0)).squeeze().cpu(), 3))\n",
    "    idx_best = torch.argmax(after[:,0])\n",
    "    _, idx_best_n = after[:,1].topk(_N)\n",
    "    best_all[fix] = mov_all[idx_best]\n",
    "    best_n_all[fix*_N:(fix+1)*_N] = mov_all[idx_best_n]\n",
    "    combined_all[fix,56:-8,48:-16,40:-24] = combined[:,:,:,:].argmax(0).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18b7840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save({'combined_all':combined_all,'best_all':best_all,'valid_t1':valid_left_t1},'optimal_reg_right.pth')\n",
    "save_str = \"left\" if LOAD_LEFT else \"right\"\n",
    "\n",
    "file_ids = [f\"{path}:var{int(idx/len(valid_t1))}\" for idx, path in enumerate(valid_t1*moving_lenn)]\n",
    "best_n_file_ids = [f\"{path}:var{int(idx/len(valid_t1))}\" for idx, path in enumerate([_n_path for _path in valid_t1 for _n_path in _N*[_path]])]\n",
    "\n",
    "nonempty_best_idxs = best_all.sum((-3,-2,-1)) > 0\n",
    "nonempty_best_n_idxs = best_n_all.sum((-3,-2,-1)) > 0\n",
    "nonempty_combined_idxs = combined_all.sum((-3,-2,-1)) > 0\n",
    "nonempty_multiple_idxs = multiple_all.sum((-3,-2,-1)) > 0\n",
    "\n",
    "print(f\"Got {nonempty_best_idxs.sum().item()} 3d labels in 'best_1'\")\n",
    "print(f\"Got {nonempty_best_n_idxs.sum().item()} 3d labels in 'best_n'\")\n",
    "print(f\"Got {nonempty_combined_idxs.sum().item()} 3d labels in 'combined'\")\n",
    "print(f\"Got {nonempty_multiple_idxs.sum().item()} 3d labels in 'multiple'\")\n",
    "\n",
    "torch.save(\n",
    "    {\n",
    "        'best_1': best_all[nonempty_best_idxs].to_sparse(),\n",
    "        'best_n': best_n_all[nonempty_best_n_idxs].to_sparse(),\n",
    "        'n': _N,\n",
    "        'combined':combined_all[nonempty_combined_idxs].to_sparse(),\n",
    "        'multiple':multiple_all[nonempty_multiple_idxs].to_sparse(),\n",
    "        'best_1_files': [_path for _path, is_non_empty in zip(file_ids[:fixed_len], nonempty_best_idxs) if is_non_empty.item()],\n",
    "        'best_n_files': [_path for _path, is_non_empty in zip(best_n_file_ids, nonempty_best_n_idxs) if is_non_empty.item()],\n",
    "        'combined_files': [_path for _path, is_non_empty in zip(file_ids[:fixed_len], nonempty_combined_idxs) if is_non_empty.item()],\n",
    "        'multiple_files': [_path for _path, is_non_empty in zip(file_ids, nonempty_multiple_idxs) if is_non_empty.item()]\n",
    "    },\n",
    "    f'multiple_reg_{save_str}.pth'\n",
    ")\n",
    "# !zip -r optimal_reg_right.zip optimal_reg_right.pth\n",
    "# !zip -r multiple_reg_right.zip multiple_reg_right.pth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2f9866",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load(f'multiple_reg_{save_str}.pth')\n",
    "print(data.keys())\n",
    "print(len(data['best_1_files']), len(data['best_n_files']), len(data['combined_files']), len(data['multiple_files']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65841530",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l optimal_reg_right.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d478a11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('after',after.mean(0),after.max(0)[0],after.min(0)[0],)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5e511e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45f4bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5,10):\n",
    "    print(dice_coeff(seg3d[fix,8:-56,48:-16,40:-24],(combined[:,:,:,1]>i).squeeze().cpu(),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3388cd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(combined[:,:,32,1])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9d9ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_centre = torch.zeros(3,60)\n",
    "cross_dice = torch.zeros(31,60,2)\n",
    "\n",
    "all_warped2 = torch.zeros(31,96,96,96)#all_warped[2]/all_warped[3]*31\n",
    "\n",
    "\n",
    "for nu1 in range(31):\n",
    "    all_disp = torch.zeros(31,96,96,96,3)\n",
    "    all_warped = torch.zeros(4,96,96,96)\n",
    "    grid = torch.stack(torch.meshgrid((torch.arange(96),torch.arange(96),torch.arange(96)))).float()\n",
    "    #print(grid.shape)\n",
    "    centre0 = torch.sum(grid.view(3,-1)*(seg2d_t2[nu1*96:(1+nu1)*96]==2).view(1,-1).float(),1)/torch.sum(seg2d_t2[nu1*96:(1+nu1)*96]==2)\n",
    "    all_dice = torch.zeros(2)\n",
    "    torch.cuda.synchronize()\n",
    "    t0 = time.time()\n",
    "    for nu in range(60):\n",
    "        img_fixed = img2d_t2[nu1*96:(1+nu1)*96].view(96,96,96)\n",
    "        img_moving = img2d[nu*96:(nu+1)*96].view(96,96,96)\n",
    "        \n",
    "        all_disp[nu] = disp\n",
    "        warped = F.grid_sample(seg2d[nu*96:(nu+1)*96].float().cuda().view(1,1,96,96,96),F.affine_grid(torch.eye(3,4).cuda().unsqueeze(0),(1,1,96,96,96))+disp.cuda(),mode='nearest')\n",
    "        warped_onehot = F.grid_sample(F.one_hot(seg2d[nu*96:(nu+1)*96],3).permute(3,0,1,2).float().cuda().view(1,3,96,96,96),F.affine_grid(torch.eye(3,4).cuda().unsqueeze(0),(1,1,96,96,96))+disp.cuda(),mode='bilinear')\n",
    "        warped_mind = F.grid_sample(mindssc_mov.float(),F.affine_grid(torch.eye(3,4).cuda().unsqueeze(0),(1,1,96,96,96))+disp.cuda(),mode='bilinear')\n",
    "\n",
    "\n",
    "        similarity = torch.exp(-1.5*F.avg_pool3d((mindssc_fix-warped_mind).pow(2),1,stride=1,padding=0).sum(1).squeeze(0))\n",
    "\n",
    "\n",
    "        #print(dice_coeff(seg2d[nu1*96:(1+nu1)*96],seg2d_t2[nu*96:(nu+1)*96],3))\n",
    "        #nib.save(nib.Nifti1Image(warped.squeeze().byte().cpu().data.numpy(),np.eye(4)),'crossmoda_reg_F'+str(nu1)+'_T2_M'+str(nu)+'_T1.nii.gz')\n",
    "        all_warped[:3] += (similarity*warped_onehot).squeeze(0).cpu()#F.one_hot(warped.squeeze().long(),3).cpu().permute(3,0,1,2)\n",
    "        all_warped[3] += similarity.squeeze().cpu()\n",
    "        d = (dice_coeff(seg2d_t2[nu1*96:(1+nu1)*96],warped.squeeze().cpu(),3))\n",
    "        all_dice += d\n",
    "        cross_dice[nu1,nu] = d\n",
    "    centre = torch.sum(grid.view(3,-1)*(all_warped[2]).view(1,-1).float(),1)/torch.sum(all_warped[2])\n",
    "    print('localisation',centre,(centre-centre0).norm(),'dice',all_dice/40)\n",
    "    torch.cuda.synchronize()\n",
    "    t1 = time.time()\n",
    "    print('time for 31 registrations',t1-t0,'sec')\n",
    "    all_centre[:,nu1] = centre\n",
    "    all_warped2[nu1] = all_warped[2]/all_warped[3]*31\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
