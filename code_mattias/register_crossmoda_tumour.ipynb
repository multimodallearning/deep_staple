{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ad7502ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Recommended gpus on this machine (descending order) ###\n",
      "  ID  Card name                     Util    Mem free  Cuda             User(s)\n",
      "----  --------------------------  ------  ----------  ---------------  -------------------\n",
      "   2  NVIDIA GeForce RTX 2080 Ti     0 %   11016 MiB  11.5(495.29.05)\n",
      "   1  NVIDIA GeForce RTX 2080 Ti     0 %    9201 MiB  11.5(495.29.05)  weihsbach\n",
      "   0  NVIDIA GeForce RTX 2080 Ti     0 %    1264 MiB  11.5(495.29.05)  ehrhardt, schneider\n",
      "   3  NVIDIA GeForce RTX 2080 Ti  ! 61 %    2135 MiB  11.5(495.29.05)  ehrhardt\n",
      "\n",
      "Will apply following mapping\n",
      "\n",
      "  ID  Card name                       torch\n",
      "----  --------------------------  --  -------\n",
      "   2  NVIDIA GeForce RTX 2080 Ti  ->  cuda:0\n",
      "1.9.0a0+gitdfbd030\n",
      "<function mind_loss at 0x7fccfcbb4160>\n"
     ]
    }
   ],
   "source": [
    "from scipy.ndimage.interpolation import map_coordinates, zoom\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import struct\n",
    "import scipy.ndimage\n",
    "from scipy.ndimage.interpolation import zoom as zoom\n",
    "from scipy.ndimage.interpolation import map_coordinates\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from meidic_vtach_utils.run_on_recommended_cuda import get_cuda_environ_vars as get_vars\n",
    "os.environ.update(get_vars(select=\"* -4\"))\n",
    "print(torch.__version__)\n",
    "import sys\n",
    "import time\n",
    "from scipy.ndimage import distance_transform_edt as edt\n",
    "\n",
    "A = torch.ones(64,64).cuda()\n",
    "A.requires_grad = True\n",
    "A.sum().backward()\n",
    "sys.path.append('/share/data_supergrover1/heinrich/voxelmorph/pytorch/')\n",
    "import losses\n",
    "print(losses.mind_loss)\n",
    "\n",
    "def gpu_usage():\n",
    "    print('gpu usage (current/max): {:.2f} / {:.2f} GB'.format(torch.cuda.memory_allocated()*1e-9, torch.cuda.max_memory_allocated()*1e-9))\n",
    "\n",
    "    \n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.ndimage.interpolation import zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "27c54686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "421\n",
      "10 no tumour\n",
      "14 no tumour\n",
      "18 no tumour\n",
      "19 / 421\n",
      "22 no tumour\n",
      "26 no tumour\n",
      "38 no tumour\n",
      "39 / 421\n",
      "42 no tumour\n",
      "46 no tumour\n",
      "58 no tumour\n",
      "59 / 421\n",
      "70 no tumour\n",
      "74 no tumour\n",
      "78 no tumour\n",
      "79 / 421\n",
      "94 no tumour\n",
      "99 / 421\n",
      "102 no tumour\n",
      "110 no tumour\n",
      "118 no tumour\n",
      "119 / 421\n",
      "130 no tumour\n",
      "139 / 421\n",
      "146 no tumour\n",
      "159 / 421\n",
      "162 no tumour\n",
      "170 no tumour\n",
      "179 / 421\n",
      "194 no tumour\n",
      "199 / 421\n",
      "206 no tumour\n",
      "219 / 421\n",
      "222 no tumour\n",
      "226 no tumour\n",
      "234 no tumour\n",
      "239 / 421\n",
      "250 no tumour\n",
      "254 no tumour\n",
      "258 no tumour\n",
      "259 / 421\n",
      "262 no tumour\n",
      "270 no tumour\n",
      "274 no tumour\n",
      "279 / 421\n",
      "282 no tumour\n",
      "294 no tumour\n",
      "299 / 421\n",
      "310 no tumour\n",
      "319 / 421\n",
      "326 no tumour\n",
      "338 no tumour\n",
      "339 / 421\n",
      "359 / 421\n",
      "362 no tumour\n",
      "366 no tumour\n",
      "370 no tumour\n",
      "374 no tumour\n",
      "378 no tumour\n",
      "379 / 421\n",
      "390 no tumour\n",
      "399 / 421\n",
      "419 / 421\n",
      "valid len 63\n"
     ]
    }
   ],
   "source": [
    "LOAD_LEFT = False\n",
    "valid_t1 = []\n",
    "folder_t1 = '/share/data_supergrover1/hansen/temp/crossMoDa/preprocessed_new/resampled/localised_crop/source_training/'\n",
    "files = sorted(os.listdir(folder_t1))\n",
    "print(len(files))\n",
    "count = 0\n",
    "img3d = torch.empty(0,128,128,128)#96,96)\n",
    "seg3d = torch.empty(0,128,128,128).long()#96,96).long()\n",
    "seg_all = torch.zeros(2,192)\n",
    "#slices = torch.zeros(2,96)\n",
    "for i,f in enumerate(files):\n",
    "    if(i%20==19):\n",
    "        print(i,'/',len(files))\n",
    "    if('128' in f):\n",
    "        continue\n",
    "    if LOAD_LEFT:\n",
    "        checkstr = 'Label_l'\n",
    "        filestr = '_ceT1_l.nii.gz'\n",
    "    else:\n",
    "        checkstr = 'Label_r'\n",
    "        filestr = '_ceT1_r.nii.gz'\n",
    "\n",
    "    if(checkstr in f):\n",
    "        #35:65\n",
    "        fsplit = f.split('_')\n",
    "        f1 = 'crossmoda_'+fsplit[1]+filestr\n",
    "        seg = torch.from_numpy(nib.load(folder_t1+f).get_fdata()).long().contiguous()\n",
    "        #print(seg.shape)\n",
    "        if((seg==1).sum()==0):\n",
    "            print(i,'no tumour')\n",
    "            continue\n",
    "        if(len(seg.unique())!=3):\n",
    "            continue\n",
    "        if(seg.shape[0]==0):\n",
    "            continue\n",
    "        valid_t1.append(f1)\n",
    "        seg3d = torch.cat((seg3d,seg.unsqueeze(0)),0)\n",
    "        img = torch.from_numpy(nib.load(folder_t1+f1).get_fdata()).float().contiguous()\n",
    "        img3d = torch.cat((img3d,img.unsqueeze(0)),0)\n",
    "\n",
    "\n",
    "\n",
    "print('valid len',len(valid_t1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "be0a0049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['crossmoda_100_ceT1_r.nii.gz', 'crossmoda_101_ceT1_r.nii.gz', 'crossmoda_11_ceT1_r.nii.gz', 'crossmoda_12_ceT1_r.nii.gz', 'crossmoda_16_ceT1_r.nii.gz', 'crossmoda_17_ceT1_r.nii.gz', 'crossmoda_19_ceT1_r.nii.gz', 'crossmoda_1_ceT1_r.nii.gz', 'crossmoda_23_ceT1_r.nii.gz', 'crossmoda_24_ceT1_r.nii.gz', 'crossmoda_25_ceT1_r.nii.gz', 'crossmoda_27_ceT1_r.nii.gz', 'crossmoda_29_ceT1_r.nii.gz', 'crossmoda_30_ceT1_r.nii.gz', 'crossmoda_32_ceT1_r.nii.gz', 'crossmoda_33_ceT1_r.nii.gz', 'crossmoda_35_ceT1_r.nii.gz', 'crossmoda_36_ceT1_r.nii.gz', 'crossmoda_37_ceT1_r.nii.gz', 'crossmoda_39_ceT1_r.nii.gz', 'crossmoda_3_ceT1_r.nii.gz', 'crossmoda_40_ceT1_r.nii.gz', 'crossmoda_42_ceT1_r.nii.gz', 'crossmoda_44_ceT1_r.nii.gz', 'crossmoda_45_ceT1_r.nii.gz', 'crossmoda_46_ceT1_r.nii.gz', 'crossmoda_47_ceT1_r.nii.gz', 'crossmoda_48_ceT1_r.nii.gz', 'crossmoda_4_ceT1_r.nii.gz', 'crossmoda_50_ceT1_r.nii.gz', 'crossmoda_52_ceT1_r.nii.gz', 'crossmoda_53_ceT1_r.nii.gz', 'crossmoda_54_ceT1_r.nii.gz', 'crossmoda_57_ceT1_r.nii.gz', 'crossmoda_59_ceT1_r.nii.gz', 'crossmoda_5_ceT1_r.nii.gz', 'crossmoda_60_ceT1_r.nii.gz', 'crossmoda_65_ceT1_r.nii.gz', 'crossmoda_68_ceT1_r.nii.gz', 'crossmoda_6_ceT1_r.nii.gz', 'crossmoda_70_ceT1_r.nii.gz', 'crossmoda_72_ceT1_r.nii.gz', 'crossmoda_73_ceT1_r.nii.gz', 'crossmoda_74_ceT1_r.nii.gz', 'crossmoda_76_ceT1_r.nii.gz', 'crossmoda_77_ceT1_r.nii.gz', 'crossmoda_78_ceT1_r.nii.gz', 'crossmoda_7_ceT1_r.nii.gz', 'crossmoda_80_ceT1_r.nii.gz', 'crossmoda_82_ceT1_r.nii.gz', 'crossmoda_83_ceT1_r.nii.gz', 'crossmoda_84_ceT1_r.nii.gz', 'crossmoda_85_ceT1_r.nii.gz', 'crossmoda_86_ceT1_r.nii.gz', 'crossmoda_91_ceT1_r.nii.gz', 'crossmoda_92_ceT1_r.nii.gz', 'crossmoda_94_ceT1_r.nii.gz', 'crossmoda_95_ceT1_r.nii.gz', 'crossmoda_96_ceT1_r.nii.gz', 'crossmoda_97_ceT1_r.nii.gz', 'crossmoda_98_ceT1_r.nii.gz', 'crossmoda_99_ceT1_r.nii.gz', 'crossmoda_9_ceT1_r.nii.gz']\n"
     ]
    }
   ],
   "source": [
    "print(valid_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fb4a255c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121\n",
      "19 / 121\n",
      "39 / 121\n",
      "59 / 121\n",
      "79 / 121\n",
      "99 / 121\n",
      "119 / 121\n",
      "valid len 30\n"
     ]
    }
   ],
   "source": [
    "valid_t2 = []\n",
    "folder_t2 = '/share/data_supergrover1/hansen/temp/crossMoDa/preprocessed_new/resampled/localised_crop/target_training/'\n",
    "\n",
    "files = sorted(os.listdir(folder_t2))\n",
    "print(len(files))\n",
    "count = 0\n",
    "img3d_t2 = torch.empty(0,128,128,128)#96,96)\n",
    "seg3d_t2 = torch.empty(0,128,128,128).long()#96,96).long()\n",
    "seg_all = torch.zeros(2,192)\n",
    "#slices = torch.zeros(2,96)\n",
    "for i,f in enumerate(files):\n",
    "    if(i%20==19):\n",
    "        print(i,'/',len(files))\n",
    "    if('128' in f):\n",
    "        continue\n",
    "    \n",
    "    if LOAD_LEFT:\n",
    "        checkstr = 'Label_l'\n",
    "        filestr = '_hrT2_l.nii.gz'\n",
    "    else:\n",
    "        checkstr = 'Label_r'\n",
    "        filestr = '_hrT2_r.nii.gz'\n",
    "\n",
    "    if(checkstr in f):\n",
    "        #35:65\n",
    "        fsplit = f.split('_')\n",
    "        f1 = 'crossmoda_'+fsplit[1]+filestr\n",
    "        seg = torch.from_numpy(nib.load(folder_t2+f).get_fdata()).long().contiguous()\n",
    "        #print(seg.shape)\n",
    "        if((seg==1).sum()==0):\n",
    "            print(i,'no tumour')\n",
    "            continue\n",
    "        if(len(seg.unique())!=3):\n",
    "            continue\n",
    "        if(seg.shape[0]==0):\n",
    "            continue\n",
    "        valid_t2.append(f1)\n",
    "        seg3d_t2 = torch.cat((seg3d_t2,seg.unsqueeze(0)),0)\n",
    "        img = torch.from_numpy(nib.load(folder_t2+f1).get_fdata()).float().contiguous()\n",
    "        img3d_t2 = torch.cat((img3d_t2,img.unsqueeze(0)),0)\n",
    "\n",
    "\n",
    "\n",
    "print('valid len',len(valid_t2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ec2410ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation layer: dense discretised displacements to compute SSD cost volume with box-filter\n",
    "def correlate(mind_fix,mind_mov,disp_hw,grid_sp,shape):\n",
    "    H = int(shape[0]); W = int(shape[1]); D = int(shape[2]);\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    t0 = time.time()\n",
    "    with torch.no_grad():\n",
    "        mind_unfold = F.unfold(F.pad(mind_mov,(disp_hw,disp_hw,disp_hw,disp_hw,disp_hw,disp_hw)).squeeze(0),disp_hw*2+1)\n",
    "        mind_unfold = mind_unfold.view(12,-1,(disp_hw*2+1)**2,W//grid_sp,D//grid_sp)\n",
    "        \n",
    "\n",
    "    ssd = torch.zeros((disp_hw*2+1)**3,H//grid_sp,W//grid_sp,D//grid_sp,dtype=mind_fix.dtype, device=mind_fix.device)#.cuda().half()\n",
    "    ssd_argmin = torch.zeros(H//grid_sp,W//grid_sp,D//grid_sp).long()\n",
    "    with torch.no_grad():\n",
    "        for i in range(disp_hw*2+1):\n",
    "            mind_sum = (mind_fix.permute(1,2,0,3,4)-mind_unfold[:,i:i+H//grid_sp]).pow(2).sum(0,keepdim=True)\n",
    "            #5,stride=1,padding=2\n",
    "            #3,stride=1,padding=1\n",
    "            ssd[i::(disp_hw*2+1)] = F.avg_pool3d(F.avg_pool3d(mind_sum.transpose(2,1),3,stride=1,padding=1),3,stride=1,padding=1).squeeze(1)\n",
    "        ssd = ssd.view(disp_hw*2+1,disp_hw*2+1,disp_hw*2+1,H//grid_sp,W//grid_sp,D//grid_sp).transpose(1,0).reshape((disp_hw*2+1)**3,H//grid_sp,W//grid_sp,D//grid_sp)\n",
    "        ssd_argmin = torch.argmin(ssd,0)#\n",
    "        #ssd = F.softmax(-ssd*1000,0)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    t1 = time.time()\n",
    "    #print(t1-t0,'sec (ssd)')\n",
    "    #gpu_usage()\n",
    "    return ssd,ssd_argmin\n",
    "\n",
    "#solve two coupled convex optimisation problems for efficient global regularisation\n",
    "def coupled_convex(ssd,ssd_argmin,disp_mesh_t,grid_sp,shape):\n",
    "    H = int(shape[0]); W = int(shape[1]); D = int(shape[2]);\n",
    "\n",
    "    disp_soft = F.avg_pool3d(disp_mesh_t.view(3,-1)[:,ssd_argmin.view(-1)].reshape(1,3,H//grid_sp,W//grid_sp,D//grid_sp),3,padding=1,stride=1)\n",
    "\n",
    "    coeffs = torch.tensor([0.003,0.01,0.03,0.1,0.3,1])\n",
    "    for j in range(6):\n",
    "        ssd_coupled_argmin = torch.zeros_like(ssd_argmin)\n",
    "        with torch.no_grad():\n",
    "            for i in range(H//grid_sp):\n",
    "\n",
    "                coupled = ssd[:,i,:,:]+coeffs[j]*(disp_mesh_t-disp_soft[:,:,i].view(3,1,-1)).pow(2).sum(0).view(-1,W//grid_sp,D//grid_sp)\n",
    "                ssd_coupled_argmin[i] = torch.argmin(coupled,0)\n",
    "            #print(coupled.shape)\n",
    "\n",
    "        disp_soft = F.avg_pool3d(disp_mesh_t.view(3,-1)[:,ssd_coupled_argmin.view(-1)].reshape(1,3,H//grid_sp,W//grid_sp,D//grid_sp),3,padding=1,stride=1)\n",
    "\n",
    "    return disp_soft\n",
    "\n",
    "#enforce inverse consistency of forward and backward transform\n",
    "def inverse_consistency(disp_field1s,disp_field2s,iter=20):\n",
    "    #factor = 1\n",
    "    B,C,H,W,D = disp_field1s.size()\n",
    "    #make inverse consistent\n",
    "    with torch.no_grad():\n",
    "        disp_field1i = disp_field1s.clone()\n",
    "        disp_field2i = disp_field2s.clone()\n",
    "\n",
    "        identity = F.affine_grid(torch.eye(3,4).unsqueeze(0),(1,1,H,W,D)).permute(0,4,1,2,3).to(disp_field1s.device).to(disp_field1s.dtype)\n",
    "        for i in range(iter):\n",
    "            disp_field1s = disp_field1i.clone()\n",
    "            disp_field2s = disp_field2i.clone()\n",
    "\n",
    "            disp_field1i = 0.5*(disp_field1s-F.grid_sample(disp_field2s,(identity+disp_field1s).permute(0,2,3,4,1)))\n",
    "            disp_field2i = 0.5*(disp_field2s-F.grid_sample(disp_field1s,(identity+disp_field2s).permute(0,2,3,4,1)))\n",
    "\n",
    "    return disp_field1i,disp_field2i\n",
    "\n",
    "def combineDeformation3d(disp_1st,disp_2nd,identity):\n",
    "    disp_composition = disp_2nd + F.grid_sample(disp_1st,disp_2nd.permute(0,2,3,4,1)+identity)\n",
    "    return disp_composition\n",
    "\n",
    "def kpts_pt(kpts_world, shape):\n",
    "    device = kpts_world.device\n",
    "    H, W, D = shape\n",
    "    return (kpts_world.flip(-1) / (torch.tensor([D, W, H]).to(device) - 1)) * 2 - 1\n",
    "\n",
    "def kpts_world(kpts_pt, shape):\n",
    "    device = kpts_pt.device\n",
    "    H, W, D = shape\n",
    "    return ((kpts_pt.flip(-1) + 1) / 2) * (torch.tensor([H, W, D]).to(device) - 1)\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TPS:\n",
    "    @staticmethod\n",
    "    def fit(c, f, lambd=0.):\n",
    "        device = c.device\n",
    "        \n",
    "        n = c.shape[0]\n",
    "        f_dim = f.shape[1]\n",
    "\n",
    "        U = TPS.u(TPS.d(c, c))\n",
    "        K = U + torch.eye(n, device=device) * lambd\n",
    "\n",
    "        P = torch.ones((n, 4), device=device)\n",
    "        P[:, 1:] = c\n",
    "\n",
    "        v = torch.zeros((n+4, f_dim), device=device)\n",
    "        v[:n, :] = f\n",
    "\n",
    "        A = torch.zeros((n+4, n+4), device=device)\n",
    "        A[:n, :n] = K\n",
    "        A[:n, -4:] = P\n",
    "        A[-4:, :n] = P.t()\n",
    "\n",
    "        theta = torch.solve(v, A)[0]\n",
    "        return theta\n",
    "        \n",
    "    @staticmethod\n",
    "    def d(a, b):\n",
    "        ra = (a**2).sum(dim=1).view(-1, 1)\n",
    "        rb = (b**2).sum(dim=1).view(1, -1)\n",
    "        dist = ra + rb - 2.0 * torch.mm(a, b.permute(1, 0))\n",
    "        dist.clamp_(0.0, float('inf'))\n",
    "        return torch.sqrt(dist)\n",
    "\n",
    "    @staticmethod\n",
    "    def u(r):\n",
    "        return (r**2) * torch.log(r + 1e-6)\n",
    "\n",
    "    @staticmethod\n",
    "    def z(x, c, theta):\n",
    "        U = TPS.u(TPS.d(x, c))\n",
    "        w, a = theta[:-4], theta[-4:].unsqueeze(2)\n",
    "        b = torch.matmul(U, w)\n",
    "        return (a[0] + a[1] * x[:, 0] + a[2] * x[:, 1] + a[3] * x[:, 2] + b.t()).t()\n",
    "    \n",
    "def thin_plate_dense(x1, y1, shape, step, lambd=.0, unroll_step_size=2**12):\n",
    "    device = x1.device\n",
    "    D, H, W = shape\n",
    "    D1, H1, W1 = D//step, H//step, W//step\n",
    "    \n",
    "    x2 = F.affine_grid(torch.eye(3, 4, device=device).unsqueeze(0), (1, 1, D1, H1, W1), align_corners=True).view(-1, 3)\n",
    "    tps = TPS()\n",
    "    theta = tps.fit(x1[0], y1[0], lambd)\n",
    "    \n",
    "    y2 = torch.zeros((1, D1 * H1 * W1, 3), device=device)\n",
    "    N = D1*H1*W1\n",
    "    n = math.ceil(N/unroll_step_size)\n",
    "    for j in range(n):\n",
    "        j1 = j * unroll_step_size\n",
    "        j2 = min((j + 1) * unroll_step_size, N)\n",
    "        y2[0, j1:j2, :] = tps.z(x2[j1:j2], x1[0], theta)\n",
    "        \n",
    "    y2 = y2.view(1, D1, H1, W1, 3).permute(0, 4, 1, 2, 3)\n",
    "    y2 = F.interpolate(y2, (D, H, W), mode='trilinear', align_corners=True).permute(0, 2, 3, 4, 1)\n",
    "    \n",
    "    return y2\n",
    "\n",
    "\n",
    "H=W=D=64\n",
    "\n",
    "#print(img_fixed.shape)\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "def dice_coeff(outputs, labels, max_label):\n",
    "    dice = torch.FloatTensor(max_label-1).fill_(0)\n",
    "    for label_num in range(1, max_label):\n",
    "        iflat = (outputs==label_num).view(-1).float()\n",
    "        tflat = (labels==label_num).view(-1).float()\n",
    "        intersection = torch.mean(iflat * tflat)\n",
    "        dice[label_num-1] = (2. * intersection) / (1e-8 + torch.mean(iflat) + torch.mean(tflat))\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "79acd039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convexAdam(img_fixed,img_moving):\n",
    "    grid_sp = 4\n",
    "    disp_hw = 8\n",
    "\n",
    "\n",
    "\n",
    "    #compute MIND descriptors and downsample (using average pooling)\n",
    "    with torch.no_grad():\n",
    "        mindssc_fix = losses.MINDSSC(img_fixed.unsqueeze(0).unsqueeze(0).cuda(),1,2).half()#*fixed_mask.cuda().half()#.cpu()\n",
    "        mindssc_mov = losses.MINDSSC(img_moving.unsqueeze(0).unsqueeze(0).cuda(),1,2).half()#*moving_mask.cuda().half()#.cpu()\n",
    "\n",
    "        mind_fix = F.avg_pool3d(mindssc_fix,grid_sp,stride=grid_sp)\n",
    "        mind_mov = F.avg_pool3d(mindssc_mov,grid_sp,stride=grid_sp)\n",
    "\n",
    "\n",
    "    ssd,ssd_argmin = correlate(mind_fix,mind_mov,disp_hw,grid_sp,(H,W,D))\n",
    "    disp_mesh_t = F.affine_grid(disp_hw*torch.eye(3,4).cuda().half().unsqueeze(0),(1,1,disp_hw*2+1,disp_hw*2+1,disp_hw*2+1),align_corners=True).permute(0,4,1,2,3).reshape(3,-1,1)\n",
    "    disp_soft = coupled_convex(ssd,ssd_argmin,disp_mesh_t,grid_sp,(H,W,D))\n",
    "    scale = torch.tensor([H//grid_sp-1,W//grid_sp-1,D//grid_sp-1]).view(1,3,1,1,1).cuda().half()/2\n",
    "    ssd_,ssd_argmin_ = correlate(mind_mov,mind_fix,disp_hw,grid_sp,(H,W,D))\n",
    "    disp_soft_ = coupled_convex(ssd_,ssd_argmin_,disp_mesh_t,grid_sp,(H,W,D))\n",
    "    disp_ice,_ = inverse_consistency((disp_soft/scale).flip(1),(disp_soft_/scale).flip(1),iter=15)\n",
    "\n",
    "    disp_hr = F.interpolate(disp_ice.flip(1)*scale*grid_sp,size=(H,W,D),mode='trilinear',align_corners=False)\n",
    "\n",
    "\n",
    "    grid_sp = 3\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        patch_mind_fix = F.avg_pool3d(mindssc_fix,grid_sp,stride=grid_sp)\n",
    "        patch_mind_mov = F.avg_pool3d(mindssc_mov,grid_sp,stride=grid_sp)\n",
    "\n",
    "\n",
    "    #create optimisable displacement grid\n",
    "    disp_lr = F.interpolate(disp_hr,size=(H//grid_sp,W//grid_sp,D//grid_sp),mode='trilinear',align_corners=False)\n",
    "\n",
    "\n",
    "    net = nn.Sequential(nn.Conv3d(3,1,(H//grid_sp,W//grid_sp,D//grid_sp),bias=False))\n",
    "    net[0].weight.data[:] = disp_lr.float().cpu().data/grid_sp\n",
    "    net.cuda()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=1)\n",
    "    #torch.cuda.synchronize()\n",
    "    #t0 = time.time()\n",
    "    grid0 = F.affine_grid(torch.eye(3,4).unsqueeze(0).cuda(),(1,1,H//grid_sp,W//grid_sp,D//grid_sp),align_corners=False)\n",
    "\n",
    "    #run Adam optimisation with diffusion regularisation and B-spline smoothing\n",
    "    lambda_weight = .6# with tps: .5, without:0.7\n",
    "    for iter in range(40):#80\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        disp_sample = F.avg_pool3d(F.avg_pool3d(F.avg_pool3d(net[0].weight,3,stride=1,padding=1),3,stride=1,padding=1),3,stride=1,padding=1).permute(0,2,3,4,1)\n",
    "        reg_loss = lambda_weight*((disp_sample[0,:,1:,:]-disp_sample[0,:,:-1,:])**2).mean()+\\\n",
    "        lambda_weight*((disp_sample[0,1:,:,:]-disp_sample[0,:-1,:,:])**2).mean()+\\\n",
    "        lambda_weight*((disp_sample[0,:,:,1:]-disp_sample[0,:,:,:-1])**2).mean()\n",
    "\n",
    "        #grid_disp = grid0.view(-1,3).cuda().float()+((disp_sample.view(-1,3))/torch.tensor([63/2,63/2,68/2]).unsqueeze(0).cuda()).flip(1)\n",
    "\n",
    "        scale = torch.tensor([(H//grid_sp-1)/2,(W//grid_sp-1)/2,(D//grid_sp-1)/2]).cuda().unsqueeze(0)\n",
    "        grid_disp = grid0.view(-1,3).cuda().float()+((disp_sample.view(-1,3))/scale).flip(1).float()\n",
    "\n",
    "        patch_mov_sampled = F.grid_sample(patch_mind_mov.float(),grid_disp.view(1,H//grid_sp,W//grid_sp,D//grid_sp,3).cuda(),align_corners=False,mode='bilinear')#,padding_mode='border')\n",
    "        #patch_mov_sampled_sq = F.grid_sample(patch_mind_mov.pow(2).float(),grid_disp.view(1,H//grid_sp,W//grid_sp,D//grid_sp,3).cuda(),align_corners=True,mode='bilinear')\n",
    "        #sampled_cost = (patch_mov_sampled_sq-2*patch_mov_sampled*patch_mind_fix+patch_mind_fix.pow(2)).mean(1)*12\n",
    "\n",
    "        sampled_cost = (patch_mov_sampled-patch_mind_fix).pow(2).mean(1)*12\n",
    "        #sampled_cost = F.grid_sample(ssd2.view(-1,1,17,17,17).float(),disp_sample.view(-1,1,1,1,3)/disp_hw,align_corners=True,padding_mode='border')\n",
    "        loss = sampled_cost.mean()\n",
    "        (loss+reg_loss).backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    fitted_grid = disp_sample.permute(0,4,1,2,3).detach()\n",
    "    #fitted_smooth = F.avg_pool3d(F.avg_pool3d(F.avg_pool3d(fitted_grid,3,padding=1,stride=1),3,padding=1,stride=1),3,padding=1,stride=1)\n",
    "    disp_hr = F.interpolate(fitted_grid*grid_sp,size=(H,W,D),mode='trilinear',align_corners=False)\n",
    "\n",
    "\n",
    "    disp_smooth = F.avg_pool3d(F.avg_pool3d(F.avg_pool3d(disp_hr,3,padding=1,stride=1),3,padding=1,stride=1),3,padding=1,stride=1)\n",
    "\n",
    "    disp = disp_smooth.cuda().float().permute(0,2,3,4,1)/torch.tensor([H-1,W-1,D-1]).cuda().view(1,1,1,1,3)*2\n",
    "    disp = disp.flip(4)\n",
    "    \n",
    "    return disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b9c9e252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([63, 128, 128, 128]) torch.Size([30, 128, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "print(img3d.shape,img3d_t2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9b3c8957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fcc17dae370>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAQVklEQVR4nO3db4wc9X3H8ffHd+c7nw32GRPXYAu7xYCQUgw68UeghECJXBoFHiAEiiq3suQntCJqpACtVClVH8CTEB5UraxA4wc0QEmoLSsicR1QFCUyHAECtjH+EyP7sH0YfGAbON+fbx/seGfndMetb2d33fw+L+m0v5nf3M7X3vvszOzM/kYRgZn98ZvT7gLMrDUcdrNEOOxmiXDYzRLhsJslwmE3S0RDYZe0VtIeSfskPVxWUWZWPs32PLukDuBd4A7gMPAqcH9E7CqvPDMrS2cDv3s9sC8iDgBIega4C5g27HPVHT3Mb2CVZvZFPuc0Z2JEU/U1EvZLgUM104eBG77oF3qYzw26vYFVmtkX2RHbp+1rJOx1kbQB2ADQQ2+zV2dm02jkA7pBYEXN9PJsXkFEbIyI/ojo76K7gdWZWSMaCfurwGpJqyTNBe4DtpRTlpmVbda78RExJunvgJ8DHcBTEbGztMrMrFQNHbNHxM+An5VUi5k1ka+gM0uEw26WCIfdLBEOu1kiHHazRDjsZolw2M0S4bCbJcJhN0uEw26WCIfdLBEOu1kiHHazRDjsZolw2M0S4bCbJcJhN0uEw26WCIfdLBEOu1kiHHazRDjsZolw2M0S4bCbJcJhN0vEjGGX9JSkIUlv18xbLGmbpL3ZY19zyzSzRtWzZf8RsHbSvIeB7RGxGtieTZvZeWzGsEfEr4CPJs2+C9iUtTcBd5dblpmVbbbH7Esj4kjWPgosLakeM2uShj+gi4gAYrp+SRskDUgaGGWk0dWZ2SzNNuzHJC0DyB6HplswIjZGRH9E9HfRPcvVmVmjZhv2LcC6rL0O2FxOOWbWLPWcevsx8FvgSkmHJa0HHgXukLQX+Its2szOY50zLRAR90/TdXvJtZhZE/kKOrNEOOxmiXDYzRLhsJslwmE3S4TDbpYIh90sEQ67WSIcdrNEOOxmiXDYzRLhsJslwmE3S4TDbpYIh90sEQ67WSIcdrNEOOxmiXDYzRLhsJslwmE3S4TDbpYIh90sEQ67WSIcdrNE1HP7pxWSXpK0S9JOSQ9m8xdL2iZpb/bY1/xyzWy26tmyjwHfiYirgRuBByRdDTwMbI+I1cD2bNrMzlMzhj0ijkTE77L2SWA3cClwF7ApW2wTcHeTajSzEpzTMbuklcC1wA5gaUQcybqOAkvLLc3MylR32CUtAH4CfDsiPqnti4gAYprf2yBpQNLAKCMNFWtms1dX2CV1UQn60xHx02z2MUnLsv5lwNBUvxsRGyOiPyL6u+guo2Yzm4V6Po0X8CSwOyK+X9O1BViXtdcBm8svz8zK0lnHMjcDfw28JemNbN4/Ao8Cz0laD7wH3NuUCs2sFDOGPSJ+DWia7tvLLcfMmsVX0JklwmE3S4TDbpYIh90sEQ67WSIcdrNEOOxmiXDYzRLhsJslwmE3S4TDbpYIh90sEQ67WSIcdrNEOOxmiXDYzRLhsJslwmE3S4TDbpYIh90sEQ67WSIcdrNEOOxmiXDYzRLhsJslop57vfVIekXSm5J2SvpeNn+VpB2S9kl6VtLc5pdrZrNVz5Z9BLgtIq4B1gBrJd0IPAY8HhGXAyeA9U2r0swaNmPYo+JUNtmV/QRwG/B8Nn8TcHczCjSzctR7f/aO7A6uQ8A2YD8wHBFj2SKHgUubUqGZlaKusEfEeESsAZYD1wNX1bsCSRskDUgaGGVkdlWaWcPO6dP4iBgGXgJuAhZJOnvL5+XA4DS/szEi+iOiv4vuRmo1swbU82n8xZIWZe15wB3AbiqhvydbbB2wuUk1mlkJOmdehGXAJkkdVN4cnouIrZJ2Ac9I+lfgdeDJJtZpZg2aMewR8Xvg2inmH6By/G5m/w/4CjqzRDjsZolw2M0S4bCbJcJhN0uEw26WCIfdLBEOu1kiHHazRDjsZolw2M0S4bCbJcJhN0uEw26WCIfdLBEOu1kiHHazRDjsZolw2M0S4bCbJcJhN0uEw26WCIfdLBEOu1kiHHazRNQd9uy2za9L2ppNr5K0Q9I+Sc9Kmtu8Ms2sUeeyZX+Qyg0dz3oMeDwiLgdOAOvLLMzMylVX2CUtB/4K+GE2LeA24PlskU3A3U2oz8xKUu+W/QfAd4GJbPoiYDgixrLpw8Cl5ZZmZmWq5/7s3wCGIuK12axA0gZJA5IGRhmZzVOYWQnquT/7zcA3Jd0J9AAXAk8AiyR1Zlv35cDgVL8cERuBjQAXanGUUrWZnbMZt+wR8UhELI+IlcB9wC8j4lvAS8A92WLrgM1Nq9LMGtbIefaHgH+QtI/KMfyT5ZRkZs1Qz258VUS8DLyctQ8A15dfkpk1g6+gM0uEw26WCIfdLBEOu1kiHHazRDjsZolw2M0S4bCbJcJhN0uEw26WCIfdLBEOu1kiHHazRDjsZolw2M0S4bCbJcJhN0vEOY1UYyWQatqT3mtjgimFx+m0xnnLbpYIh90sEd6Nb7E58+ZN3zmR78ZH7a77+HhhsZiI2onic3iX36bhLbtZIhx2s0Q47GaJ8DF7M8zpyJvze4tdSxZX2xML5xf6dGYsX+7EJ/lyp04XlotTp2omfIxu9akr7JIOAieBcWAsIvolLQaeBVYCB4F7I+JEc8o0s0ady2781yJiTUT0Z9MPA9sjYjWwPZs2s/NUI7vxdwG3Zu1NVO4B91CD9fxR6Fh4YbWthRcU+j694uJqe6Sv+N/fdTo/jdZ7KO/TxKTTa7W78WZ1qnfLHsAvJL0maUM2b2lEHMnaR4GlpVdnZqWpd8t+S0QMSvoSsE3SO7WdERGSpvykKHtz2ADQQ+9Ui5hZC9S1ZY+IwexxCHiByq2aj0laBpA9Dk3zuxsjoj8i+rvoLqdqMztnM27ZJc0H5kTEyaz9deBfgC3AOuDR7HFzMwttmZpvpamzq9jV1Tn1cguKp9BYvLDaHFtYvDz21CX5c45Peu8b68lP2XUfz5frHBvDrFH17MYvBV5Q5Y+7E/iviHhR0qvAc5LWA+8B9zavTDNr1Ixhj4gDwDVTzP8QuL0ZRZlZ+XwF3SSaO7fanrNyRaHv9Or86rfRBfnHHaO9Kiw3Ni+fHukrPv+cmj1yTTqj1jESNcvVdI56N94a52vjzRLhsJslwmE3S4SP2Wu+oQYw5/KV1fbgHRcV+k6uqjmO7jtTbfYuGCkst6j3s/z5Rov/xcP78+P+nmPF99qO0fyYXSOj1fbESPH5zWbDW3azRDjsZolIfje+85I/KUy//9V81/309Z8W+i67OP+6/jWLB6vtlT3HC8t9uedQtf3b06sLfU8O3VJt68jcQl/3cH6YMOdE/s22sTNnCst5wAqbDW/ZzRLhsJslIsndeHXm/+zRFUsKfZ9cke9Kr1gyXOj7ct/71faNC/ZX29f1HC4sd0VX/sWYtz7/vLjuU/m6535c3B2fvz8/TJj48KO8w7vtVgJv2c0S4bCbJcJhN0tEksfsdORXzY33Fv8LJrrzY/bujuK3zVb2fFhtr+j6kOm8+Gk+KsXm94vfDu4+kb+/9h4v3sONwWN5HZ99hlmZvGU3S4TDbpaINHfja26B3DVcPDXW+XE+5vuZieKXZEYjn/488jHidp25sLDcfxz6arX93rvFK/T6juSn0RYcLN7WaeKzmlp8us1K5i27WSIcdrNEOOxmiUjymD1qjtk7jxZvPNv3Tn78/d6y4uAVHy/Jx4A/eCa/Z9tvPr68sNz+o3lf91DxuH/h/nwgijl/eL/QNz42ilmzeMtulgiH3SwRSe7G157Wiknju/Ueq7lq7mTx9k/DY/mNKU9O9FTbH4wsKD79kbzvgoPFU2jzDuRX3o19VDyE8Ok2a6a6tuySFkl6XtI7knZLuknSYknbJO3NHvtmfiYza5d6d+OfAF6MiKuo3ApqN/AwsD0iVgPbs2kzO0/VcxfXhcBXgL8BiIgzwBlJdwG3ZottAl4GHmpGkc1UO5AFwPi8/P0v5hW/qHJJ93C1XXs13eAnxSvouo/nz9G3+2Shb+JozZ2tvdtuLVTPln0V8AHwn5Jel/TD7NbNSyPiSLbMUSp3ezWz81Q9Ye8ErgP+PSKuBU4zaZc9IgKYcjMlaYOkAUkDo/hmB2btUk/YDwOHI2JHNv08lfAfk7QMIHscmuqXI2JjRPRHRH8X3VMtYmYtUM/92Y9KOiTpyojYQ+We7Luyn3XAo9nj5qZWWqaaWz5NnC6ODd8xkg9e0fFR8dTbr4//WbU9Hvn75MmdxSvtlr+a78F07C0ORjnuQSmsTeo9z/73wNOS5gIHgL+lslfwnKT1wHvAvc0p0czKUFfYI+INoH+KrttLrcbMmibNK+gm8lNq8fmkK+gODFfbX7qguHt++Phl1XZXfncmVuwuPkf36weq7fHh4UKfT7dZu/jaeLNEOOxmiXDYzRKR5jF7jRgt3g55fE9+vL3o+HChb9Ec5b93Mj9on5h03D8+MWk8eLPzgLfsZolw2M0SoWjhqSBJH1C5AGcJcLxlK57a+VADuI7JXEfRudZxWURcPFVHS8NeXak0EBFTXaSTVA2uw3W0sg7vxpslwmE3S0S7wr6xTeutdT7UAK5jMtdRVFodbTlmN7PW8268WSJaGnZJayXtkbRPUstGo5X0lKQhSW/XzGv5UNiSVkh6SdIuSTslPdiOWiT1SHpF0ptZHd/L5q+StCN7fZ7Nxi9oOkkd2fiGW9tVh6SDkt6S9IakgWxeO/5GmjZse8vCLqkD+DfgL4GrgfslXd2i1f8IWDtpXjuGwh4DvhMRVwM3Ag9k/wetrmUEuC0irgHWAGsl3Qg8BjweEZcDJ4D1Ta7jrAepDE9+Vrvq+FpErKk51dWOv5HmDdseES35AW4Cfl4z/QjwSAvXvxJ4u2Z6D7Asay8D9rSqlpoaNgN3tLMWoBf4HXADlYs3Oqd6vZq4/uXZH/BtwFZAbarjILBk0ryWvi7AQuAPZJ+llV1HK3fjLwUO1Uwfzua1S1uHwpa0ErgW2NGOWrJd5zeoDBS6DdgPDEfE2ftfter1+QHwXeDs4H8XtamOAH4h6TVJG7J5rX5dmjpsuz+g44uHwm4GSQuAnwDfjohP2lFLRIxHxBoqW9brgauavc7JJH0DGIqI11q97incEhHXUTnMfEDSV2o7W/S6NDRs+0xaGfZBYEXN9PJsXrvUNRR22SR1UQn60xHx03bWAhARw8BLVHaXF0k6+7XnVrw+NwPflHQQeIbKrvwTbaiDiBjMHoeAF6i8Abb6dWlo2PaZtDLsrwKrs09a5wL3AVtauP7JtlAZAhtaNBS2JAFPArsj4vvtqkXSxZIWZe15VD432E0l9Pe0qo6IeCQilkfESip/D7+MiG+1ug5J8yVdcLYNfB14mxa/LhFxFDgk6cps1tlh28upo9kffEz6oOFO4F0qx4f/1ML1/hg4AoxSefdcT+XYcDuwF/hfYHEL6riFyi7Y74E3sp87W10L8OfA61kdbwP/nM3/U+AVYB/w30B3C1+jW4Gt7agjW9+b2c/Os3+bbfobWQMMZK/N/wB9ZdXhK+jMEuEP6MwS4bCbJcJhN0uEw26WCIfdLBEOu1kiHHazRDjsZon4P1+sR8A+AwNXAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow((seg3d==2).sum(0).sum(-1)[8:-56,48:-16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "436933d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fcc17cf5cd0>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow((seg3d==1).sum(0).sum(-1)[56:-8,48:-16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "57ae386c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fcc17c9bd00>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow((seg3d==1).sum(0).sum(-2)[8:-56,40:-24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7dd6a4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0006079673767089844 sec (total)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data_supergrover1/weihsbach/shared_data/tmp/curriculum_deeplab/.venv/lib/python3.9/site-packages/torch/nn/functional.py:4043: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "/share/data_supergrover1/weihsbach/shared_data/tmp/curriculum_deeplab/.venv/lib/python3.9/site-packages/torch/nn/functional.py:3981: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before tensor([0.3380, 0.5127]) tensor([0.6481, 0.7113])\n",
      "after tensor([0.5046, 0.4496]) tensor([0.8667, 0.5619]) tensor([0.0000, 0.2416])\n",
      "combined tensor([0.7994, 0.4373])\n",
      "1 9.106754779815674 sec (total)\n",
      "before tensor([0.1036, 0.3853]) tensor([0.3723, 0.5042])\n",
      "after tensor([0.1378, 0.3819]) tensor([0.5427, 0.4677]) tensor([0.0000, 0.2762])\n",
      "combined tensor([0.2058, 0.3968])\n",
      "2 18.594473123550415 sec (total)\n",
      "before tensor([0.1672, 0.5298]) tensor([0.4667, 0.6609])\n",
      "after tensor([0.2705, 0.4720]) tensor([0.7196, 0.6538]) tensor([0.0000, 0.2550])\n",
      "combined tensor([0.2666, 0.3874])\n",
      "3 27.266937255859375 sec (total)\n",
      "before tensor([0.4186, 0.5803]) tensor([0.8167, 0.7670])\n",
      "after tensor([0.5700, 0.4937]) tensor([0.8617, 0.6657]) tensor([0.0000, 0.3488])\n",
      "combined tensor([0.8980, 0.4234])\n",
      "4 36.773253202438354 sec (total)\n",
      "before tensor([0.3197, 0.5645]) tensor([0.7183, 0.7030])\n",
      "after tensor([0.4453, 0.4213]) tensor([0.8818, 0.6061]) tensor([0.0000, 0.2113])\n",
      "combined tensor([0.5880, 0.3854])\n",
      "5 46.497188568115234 sec (total)\n",
      "before tensor([0.2793, 0.5361]) tensor([0.5743, 0.6819])\n",
      "after tensor([0.3639, 0.5449]) tensor([0.8158, 0.7220]) tensor([0.0000, 0.3389])\n",
      "combined tensor([0.4075, 0.4751])\n",
      "6 55.46262764930725 sec (total)\n",
      "before tensor([0.2426, 0.5062]) tensor([0.6255, 0.6501])\n",
      "after tensor([0.4234, 0.5433]) tensor([0.7971, 0.6924]) tensor([0.0000, 0.3731])\n",
      "combined tensor([0.5756, 0.5149])\n",
      "7 64.94224309921265 sec (total)\n",
      "before tensor([0.2711, 0.4807]) tensor([0.6662, 0.7062])\n",
      "after tensor([0.5335, 0.4840]) tensor([0.8284, 0.6246]) tensor([0.0000, 0.3160])\n",
      "combined tensor([0.8184, 0.5181])\n",
      "8 73.5995545387268 sec (total)\n",
      "before tensor([0.2995, 0.5234]) tensor([0.6660, 0.7347])\n",
      "after tensor([0.4133, 0.4584]) tensor([0.8419, 0.6292]) tensor([0.0000, 0.2469])\n",
      "combined tensor([0.4785, 0.3792])\n",
      "9 81.68172717094421 sec (total)\n",
      "before tensor([0.1157, 0.4872]) tensor([0.4050, 0.6967])\n",
      "after tensor([0.2078, 0.5147]) tensor([0.7153, 0.6702]) tensor([0.0000, 0.3068])\n",
      "combined tensor([0.2231, 0.4331])\n",
      "10 91.16556215286255 sec (total)\n",
      "before tensor([0.3298, 0.5876]) tensor([0.7686, 0.7090])\n",
      "after tensor([0.4558, 0.4861]) tensor([0.8590, 0.6910]) tensor([0.0000, 0.3297])\n",
      "combined tensor([0.6368, 0.4460])\n",
      "11 100.6683075428009 sec (total)\n",
      "before tensor([0.3088, 0.4922]) tensor([0.5747, 0.6730])\n",
      "after tensor([0.5013, 0.5011]) tensor([0.8196, 0.6567]) tensor([0.0000, 0.3221])\n",
      "combined tensor([0.7127, 0.5736])\n",
      "12 111.13979053497314 sec (total)\n",
      "before tensor([0.3423, 0.5430]) tensor([0.7306, 0.6975])\n",
      "after tensor([0.4527, 0.5279]) tensor([0.8234, 0.6866]) tensor([0.0000, 0.2849])\n",
      "combined tensor([0.7400, 0.4502])\n",
      "13 120.73058104515076 sec (total)\n",
      "before tensor([0.1167, 0.4405]) tensor([0.4708, 0.6532])\n",
      "after tensor([0.2643, 0.5090]) tensor([0.7125, 0.6919]) tensor([0.0000, 0.2453])\n",
      "combined tensor([0.3719, 0.5245])\n",
      "14 130.1422712802887 sec (total)\n",
      "before tensor([0.3072, 0.5484]) tensor([0.7809, 0.7528])\n",
      "after tensor([0.3672, 0.4786]) tensor([0.8763, 0.6258]) tensor([0.0000, 0.2542])\n",
      "combined tensor([0.3537, 0.4112])\n",
      "15 139.7214000225067 sec (total)\n",
      "before tensor([0.3326, 0.6349]) tensor([0.6046, 0.7616])\n",
      "after tensor([0.5164, 0.5913]) tensor([0.8458, 0.7473]) tensor([0.0000, 0.3343])\n",
      "combined tensor([0.8030, 0.5995])\n",
      "16 148.8835859298706 sec (total)\n",
      "before tensor([0.2888, 0.6192]) tensor([0.6170, 0.7477])\n",
      "after tensor([0.4547, 0.5235]) tensor([0.8479, 0.6856]) tensor([0.0000, 0.3394])\n",
      "combined tensor([0.6313, 0.5244])\n",
      "17 158.63730120658875 sec (total)\n",
      "before tensor([0.3484, 0.3975]) tensor([0.7077, 0.6278])\n",
      "after tensor([0.4931, 0.4287]) tensor([0.8263, 0.5936]) tensor([0.0000, 0.1755])\n",
      "combined tensor([0.7804, 0.3741])\n",
      "18 168.25030183792114 sec (total)\n",
      "before tensor([0.3413, 0.4781]) tensor([0.7351, 0.6296])\n",
      "after tensor([0.4406, 0.4455]) tensor([0.7498, 0.6497]) tensor([0.0000, 0.2503])\n",
      "combined tensor([0.6402, 0.4000])\n",
      "19 176.95534300804138 sec (total)\n",
      "before tensor([0.2177, 0.5908]) tensor([0.6231, 0.7456])\n",
      "after tensor([0.2942, 0.5766]) tensor([0.6771, 0.6888]) tensor([0.0000, 0.4250])\n",
      "combined tensor([0.3749, 0.5352])\n",
      "20 186.08079648017883 sec (total)\n",
      "before tensor([0.3037, 0.5104]) tensor([0.6312, 0.6486])\n",
      "after tensor([0.4812, 0.4184]) tensor([0.8378, 0.5637]) tensor([0.0000, 0.3301])\n",
      "combined tensor([0.8156, 0.4604])\n",
      "21 195.5046992301941 sec (total)\n",
      "before tensor([0.0563, 0.5156]) tensor([0.3979, 0.7664])\n",
      "after tensor([0.1350, 0.4321]) tensor([0.7088, 0.6548]) tensor([0.0000, 0.2727])\n",
      "combined tensor([0.1130, 0.3812])\n",
      "22 204.51413869857788 sec (total)\n",
      "before tensor([0.2819, 0.5110]) tensor([0.7592, 0.5971])\n",
      "after tensor([0.3442, 0.4767]) tensor([0.8513, 0.6242]) tensor([0.0000, 0.1103])\n",
      "combined tensor([0.2980, 0.4300])\n",
      "23 214.30306267738342 sec (total)\n",
      "before tensor([0.3290, 0.6154]) tensor([0.6168, 0.7433])\n",
      "after tensor([0.4319, 0.5543]) tensor([0.7804, 0.7190]) tensor([0.0000, 0.2656])\n",
      "combined tensor([0.6006, 0.5829])\n",
      "24 223.70996809005737 sec (total)\n",
      "before tensor([0.3582, 0.6071]) tensor([0.7070, 0.7308])\n",
      "after tensor([0.5274, 0.4495]) tensor([0.8245, 0.5885]) tensor([0.0000, 0.2261])\n",
      "combined tensor([0.7955, 0.4925])\n",
      "25 233.1314582824707 sec (total)\n",
      "before tensor([0.3770, 0.5853]) tensor([0.6941, 0.7751])\n",
      "after tensor([0.5108, 0.5507]) tensor([0.8441, 0.6778]) tensor([0.0000, 0.4315])\n",
      "combined tensor([0.8358, 0.5571])\n",
      "26 242.47464799880981 sec (total)\n",
      "before tensor([0.2397, 0.4878]) tensor([0.5658, 0.6717])\n",
      "after tensor([0.3616, 0.4408]) tensor([0.8237, 0.6470]) tensor([0.0000, 0.2280])\n",
      "combined tensor([0.4078, 0.3735])\n",
      "27 251.6488540172577 sec (total)\n",
      "before tensor([0.2179, 0.6111]) tensor([0.5689, 0.7604])\n",
      "after tensor([0.3884, 0.4997]) tensor([0.8372, 0.6719]) tensor([0.0000, 0.3200])\n",
      "combined tensor([0.5049, 0.5273])\n",
      "28 260.693528175354 sec (total)\n",
      "before tensor([0.3012, 0.4198]) tensor([0.6051, 0.5697])\n",
      "after tensor([0.3588, 0.4304]) tensor([0.8066, 0.5827]) tensor([0.0000, 0.2824])\n",
      "combined tensor([0.4237, 0.3841])\n",
      "29 270.766991853714 sec (total)\n",
      "before tensor([0.3237, 0.5415]) tensor([0.6531, 0.7302])\n",
      "after tensor([0.4642, 0.4570]) tensor([0.8318, 0.6569]) tensor([0.0000, 0.3229])\n",
      "combined tensor([0.6807, 0.4465])\n",
      "30 280.2351059913635 sec (total)\n",
      "before tensor([0.4038, 0.5983]) tensor([0.6760, 0.7023])\n",
      "after tensor([0.5492, 0.5082]) tensor([0.8516, 0.6902]) tensor([0.0000, 0.3184])\n",
      "combined tensor([0.8509, 0.4687])\n",
      "31 289.4368999004364 sec (total)\n",
      "before tensor([0.0866, 0.3905]) tensor([0.3136, 0.6187])\n",
      "after tensor([0.1997, 0.4444]) tensor([0.5695, 0.6939]) tensor([0.0000, 0.1562])\n",
      "combined tensor([0.2209, 0.4165])\n",
      "32 298.3352656364441 sec (total)\n",
      "before tensor([0.2409, 0.5666]) tensor([0.6996, 0.6632])\n",
      "after tensor([0.2749, 0.4350]) tensor([0.7725, 0.6630]) tensor([0.0000, 0.2531])\n",
      "combined tensor([0.3101, 0.3868])\n",
      "33 307.91789150238037 sec (total)\n",
      "before tensor([0.4110, 0.5636]) tensor([0.7347, 0.6810])\n",
      "after tensor([0.4939, 0.4696]) tensor([0.8649, 0.6513]) tensor([0.0000, 0.2674])\n",
      "combined tensor([0.7981, 0.4108])\n",
      "34 317.1852984428406 sec (total)\n",
      "before tensor([0.3638, 0.5751]) tensor([0.7418, 0.7419])\n",
      "after tensor([0.5520, 0.6267]) tensor([0.8637, 0.7397]) tensor([0.0000, 0.4000])\n",
      "combined tensor([0.8090, 0.6273])\n",
      "35 325.821635723114 sec (total)\n",
      "before tensor([0.3692, 0.4782]) tensor([0.6854, 0.7094])\n",
      "after tensor([0.5462, 0.4764]) tensor([0.8795, 0.6737]) tensor([0.0000, 0.2205])\n",
      "combined tensor([0.8079, 0.3913])\n",
      "36 335.3008370399475 sec (total)\n",
      "before tensor([0.4007, 0.5582]) tensor([0.7975, 0.7612])\n",
      "after tensor([0.5977, 0.5822]) tensor([0.8549, 0.7209]) tensor([0.0000, 0.4060])\n",
      "combined tensor([0.8950, 0.5750])\n",
      "37 344.79076051712036 sec (total)\n",
      "before tensor([0.3020, 0.4816]) tensor([0.7830, 0.6424])\n",
      "after tensor([0.3791, 0.4696]) tensor([0.8836, 0.6080]) tensor([0.0000, 0.3048])\n",
      "combined tensor([0.3558, 0.4192])\n",
      "38 354.8932659626007 sec (total)\n",
      "before tensor([0.2602, 0.5503]) tensor([0.4772, 0.7344])\n",
      "after tensor([0.3698, 0.5052]) tensor([0.7168, 0.6775]) tensor([0.0000, 0.3240])\n",
      "combined tensor([0.5120, 0.4528])\n",
      "39 364.1917884349823 sec (total)\n",
      "before tensor([0.2579, 0.5372]) tensor([0.6445, 0.7832])\n",
      "after tensor([0.3372, 0.4762]) tensor([0.7769, 0.7331]) tensor([0.0000, 0.1154])\n",
      "combined tensor([0.4128, 0.3641])\n",
      "40 370.98767280578613 sec (total)\n",
      "before tensor([0.0728, 0.5342]) tensor([0.1906, 0.7572])\n",
      "after tensor([0.1000, 0.5064]) tensor([0.1955, 0.6718]) tensor([0.0000, 0.2983])\n",
      "combined tensor([0.0834, 0.4589])\n",
      "41 379.5498616695404 sec (total)\n",
      "before tensor([0.4120, 0.5427]) tensor([0.7404, 0.7388])\n",
      "after tensor([0.5766, 0.5397]) tensor([0.8796, 0.6930]) tensor([0.0000, 0.2718])\n",
      "combined tensor([0.8876, 0.4946])\n",
      "42 389.4844048023224 sec (total)\n",
      "before tensor([0.3128, 0.5723]) tensor([0.7378, 0.7778])\n",
      "after tensor([0.3886, 0.5460]) tensor([0.8157, 0.7286]) tensor([0.0000, 0.3609])\n",
      "combined tensor([0.4226, 0.4491])\n",
      "43 398.75134086608887 sec (total)\n",
      "before tensor([0.3023, 0.4597]) tensor([0.4558, 0.7075])\n",
      "after tensor([0.4869, 0.4520]) tensor([0.8177, 0.6117]) tensor([0.0000, 0.1427])\n",
      "combined tensor([0.7050, 0.4516])\n",
      "44 408.0024857521057 sec (total)\n",
      "before tensor([0.1494, 0.5419]) tensor([0.4251, 0.6998])\n",
      "after tensor([0.2484, 0.4052]) tensor([0.6806, 0.6761]) tensor([0.0000, 0.0931])\n",
      "combined tensor([0.3229, 0.3945])\n",
      "45 417.62826657295227 sec (total)\n",
      "before tensor([0.2989, 0.3929]) tensor([0.6174, 0.6179])\n",
      "after tensor([0.3800, 0.4033]) tensor([0.7561, 0.6229]) tensor([0.0000, 0.2503])\n",
      "combined tensor([0.6418, 0.3746])\n",
      "46 426.97268772125244 sec (total)\n",
      "before tensor([0.3437, 0.3514]) tensor([0.7155, 0.4988])\n",
      "after tensor([0.4654, 0.3507]) tensor([0.8492, 0.4755]) tensor([0.0000, 0.2011])\n",
      "combined tensor([0.7948, 0.3944])\n",
      "47 435.05053186416626 sec (total)\n",
      "before tensor([0.2080, 0.5125]) tensor([0.5169, 0.7089])\n",
      "after tensor([0.2579, 0.4177]) tensor([0.7471, 0.5797]) tensor([0.0000, 0.1290])\n",
      "combined tensor([0.3052, 0.4200])\n",
      "48 444.65732526779175 sec (total)\n",
      "before tensor([0.3822, 0.5099]) tensor([0.7129, 0.6642])\n",
      "after tensor([0.5266, 0.5313]) tensor([0.8340, 0.6756]) tensor([0.0000, 0.3731])\n",
      "combined tensor([0.7910, 0.4653])\n",
      "49 454.2701041698456 sec (total)\n",
      "before tensor([0.3327, 0.5216]) tensor([0.7684, 0.6871])\n",
      "after tensor([0.4475, 0.5225]) tensor([0.8673, 0.7020]) tensor([0.0000, 0.3115])\n",
      "combined tensor([0.5568, 0.4440])\n",
      "50 463.27703619003296 sec (total)\n",
      "before tensor([0.3697, 0.5568]) tensor([0.7285, 0.7445])\n",
      "after tensor([0.5178, 0.4832]) tensor([0.8877, 0.6525]) tensor([0.0000, 0.2915])\n",
      "combined tensor([0.7638, 0.4267])\n",
      "51 472.9342038631439 sec (total)\n",
      "before tensor([0.2866, 0.4827]) tensor([0.6121, 0.7122])\n",
      "after tensor([0.4392, 0.4809]) tensor([0.8404, 0.6326]) tensor([0.0000, 0.3380])\n",
      "combined tensor([0.5864, 0.4576])\n",
      "52 482.73069047927856 sec (total)\n",
      "before tensor([0.2907, 0.5091]) tensor([0.4839, 0.7195])\n",
      "after tensor([0.4087, 0.4771]) tensor([0.7662, 0.6012]) tensor([0.0000, 0.3188])\n",
      "combined tensor([0.6575, 0.4535])\n",
      "53 492.08273363113403 sec (total)\n",
      "before tensor([0.3668, 0.4574]) tensor([0.6664, 0.6335])\n",
      "after tensor([0.5701, 0.5304]) tensor([0.8923, 0.6825]) tensor([0.0000, 0.3515])\n",
      "combined tensor([0.8248, 0.5131])\n",
      "54 501.5630946159363 sec (total)\n",
      "before tensor([0.3571, 0.5624]) tensor([0.7369, 0.7148])\n",
      "after tensor([0.5172, 0.5572]) tensor([0.8259, 0.7127]) tensor([0.0000, 0.3109])\n",
      "combined tensor([0.6914, 0.5363])\n",
      "55 510.25193905830383 sec (total)\n",
      "before tensor([0.3636, 0.4934]) tensor([0.7702, 0.6527])\n",
      "after tensor([0.5634, 0.3537]) tensor([0.9048, 0.5400]) tensor([0.0000, 0.1073])\n",
      "combined tensor([0.7963, 0.2962])\n",
      "56 519.9142656326294 sec (total)\n",
      "before tensor([0.3302, 0.5204]) tensor([0.7246, 0.7693])\n",
      "after tensor([0.5440, 0.6114]) tensor([0.8780, 0.7025]) tensor([0.0000, 0.4642])\n",
      "combined tensor([0.7884, 0.5958])\n",
      "57 529.6830930709839 sec (total)\n",
      "before tensor([0.3176, 0.5371]) tensor([0.7791, 0.7092])\n",
      "after tensor([0.4130, 0.5161]) tensor([0.8487, 0.7326]) tensor([0.0000, 0.2731])\n",
      "combined tensor([0.4308, 0.4409])\n",
      "58 539.1884243488312 sec (total)\n",
      "before tensor([0.3319, 0.4804]) tensor([0.6779, 0.6879])\n",
      "after tensor([0.4627, 0.5724]) tensor([0.8524, 0.6900]) tensor([0.0000, 0.3628])\n",
      "combined tensor([0.6515, 0.5384])\n",
      "59 548.3975338935852 sec (total)\n",
      "before tensor([0.2913, 0.5829]) tensor([0.7503, 0.6927])\n",
      "after tensor([0.4627, 0.5084]) tensor([0.8371, 0.7293]) tensor([0.0000, 0.2892])\n",
      "combined tensor([0.7019, 0.4749])\n",
      "60 558.3014905452728 sec (total)\n",
      "before tensor([0.3479, 0.5688]) tensor([0.7081, 0.6888])\n",
      "after tensor([0.4594, 0.3639]) tensor([0.8104, 0.5640]) tensor([0.0000, 0.0963])\n",
      "combined tensor([0.7234, 0.3752])\n",
      "61 566.7776162624359 sec (total)\n",
      "before tensor([0.0000, 0.5516]) tensor([0.0000, 0.7670])\n",
      "after tensor([0.0000, 0.4803]) tensor([0.0000, 0.6486]) tensor([0.0000, 0.2542])\n",
      "combined tensor([0.0000, 0.4266])\n",
      "62 576.4803740978241 sec (total)\n",
      "before tensor([0.2826, 0.5697]) tensor([0.5002, 0.7317])\n",
      "after tensor([0.4611, 0.5142]) tensor([0.7506, 0.6534]) tensor([0.0000, 0.3195])\n",
      "combined tensor([0.6516, 0.5771])\n"
     ]
    }
   ],
   "source": [
    "moving_lenn = len(valid_t2)\n",
    "_N = 4\n",
    "\n",
    "best_all = torch.zeros_like(img3d)\n",
    "best_n_all = torch.zeros_like(img3d).repeat(_N,1,1,1)\n",
    "combined_all = torch.zeros_like(img3d)\n",
    "multiple_all = torch.zeros_like(img3d).repeat(moving_lenn,1,1,1)\n",
    "\n",
    "fixed_len = img3d.shape[0]\n",
    "\n",
    "import time\n",
    "t0 = time.time()\n",
    "for fix in range(fixed_len):\n",
    "    print(fix,time.time()-t0,'sec (total)')\n",
    "    before = torch.zeros(moving_lenn,2)\n",
    "    after = torch.zeros(moving_lenn,2)\n",
    "    combined = torch.zeros(3,64,64,64)\n",
    "    mov_all = torch.zeros(moving_lenn,128,128,128)\n",
    "\n",
    "    for i in range(moving_lenn):\n",
    "        disp = convexAdam(img3d[fix,56:-8,48:-16,40:-24],img3d_t2[i,56:-8,48:-16,40:-24])\n",
    "        warped_one_hot = F.grid_sample(F.one_hot(seg3d_t2[i,56:-8,48:-16,40:-24].long(),3).permute(3,0,1,2).float().cuda().view(1,3,H,W,D),F.affine_grid(torch.eye(3,4).cuda().unsqueeze(0),(1,1,H,W,D))+disp.cuda(),mode='bilinear')\n",
    "        combined += warped_one_hot.squeeze().cpu()\n",
    "        warped_seg = warped_one_hot.argmax(1).squeeze()\n",
    "        mov_all[i,56:-8,48:-16,40:-24] = warped_seg\n",
    "        multiple_all[fix*i] = mov_all[i]\n",
    "        before[i] = (dice_coeff(seg3d[fix,56:-8,48:-16,40:-24],seg3d_t2[i,56:-8,48:-16,40:-24],3))\n",
    "        after[i] = (dice_coeff(seg3d[fix,56:-8,48:-16,40:-24],warped_seg.squeeze().cpu(),3))\n",
    "    combined = F.avg_pool3d(F.avg_pool3d(F.avg_pool3d(combined.unsqueeze(0),3,stride=1,padding=1),3,stride=1,padding=1),3,stride=1,padding=1).squeeze()\n",
    "    combined[0] *= 0.66\n",
    "    print('before', before.mean(0), before.max(0)[0])\n",
    "    print('after', after.mean(0), after.max(0)[0], after.min(0)[0],)\n",
    "    print('combined', dice_coeff(seg3d[fix,56:-8,48:-16,40:-24], (combined[:,:,:,:].argmax(0)).squeeze().cpu(), 3))\n",
    "    idx_best = torch.argmax(after[:,0])\n",
    "    _, idx_best_n = after[:,1].topk(_N)\n",
    "    best_all[fix] = mov_all[idx_best]\n",
    "    best_n_all[fix*_N:(fix+1)*_N] = mov_all[idx_best_n]\n",
    "    combined_all[fix,56:-8,48:-16,40:-24] = combined[:,:,:,:].argmax(0).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e18b7840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 63 3d labels in 'best_1'\n",
      "Got 252 3d labels in 'best_n'\n",
      "Got 63 3d labels in 'combined'\n",
      "Got 753 3d labels in 'multiple'\n"
     ]
    }
   ],
   "source": [
    "# torch.save({'combined_all':combined_all,'best_all':best_all,'valid_t1':valid_left_t1},'optimal_reg_right.pth')\n",
    "save_str = \"left\" if LOAD_LEFT else \"right\"\n",
    "\n",
    "file_ids = [f\"{path}:var{int(idx/len(valid_t1))}\" for idx, path in enumerate(valid_t1*moving_lenn)]\n",
    "\n",
    "best_n_file_ids = []\n",
    "for _path in valid_t1:\n",
    "    for n in range(_N):\n",
    "        best_n_file_ids.append(f\"{_path}:var{n}\")\n",
    "\n",
    "nonempty_best_idxs = best_all.sum((-3,-2,-1)) > 0\n",
    "nonempty_best_n_idxs = best_n_all.sum((-3,-2,-1)) > 0\n",
    "nonempty_combined_idxs = combined_all.sum((-3,-2,-1)) > 0\n",
    "nonempty_multiple_idxs = multiple_all.sum((-3,-2,-1)) > 0\n",
    "\n",
    "print(f\"Got {nonempty_best_idxs.sum().item()} 3d labels in 'best_1'\")\n",
    "print(f\"Got {nonempty_best_n_idxs.sum().item()} 3d labels in 'best_n'\")\n",
    "print(f\"Got {nonempty_combined_idxs.sum().item()} 3d labels in 'combined'\")\n",
    "print(f\"Got {nonempty_multiple_idxs.sum().item()} 3d labels in 'multiple'\")\n",
    "\n",
    "torch.save(\n",
    "    {\n",
    "        'best_1': best_all[nonempty_best_idxs].to_sparse(),\n",
    "        'best_n': best_n_all[nonempty_best_n_idxs].to_sparse(),\n",
    "        'n': _N,\n",
    "        'combined':combined_all[nonempty_combined_idxs].to_sparse(),\n",
    "        'multiple':multiple_all[nonempty_multiple_idxs].to_sparse(),\n",
    "        'best_1_files': [_path for _path, is_non_empty in zip(file_ids[:fixed_len], nonempty_best_idxs) if is_non_empty.item()],\n",
    "        'best_n_files': [_path for _path, is_non_empty in zip(best_n_file_ids, nonempty_best_n_idxs) if is_non_empty.item()],\n",
    "        'combined_files': [_path for _path, is_non_empty in zip(file_ids[:fixed_len], nonempty_combined_idxs) if is_non_empty.item()],\n",
    "        'multiple_files': [_path for _path, is_non_empty in zip(file_ids, nonempty_multiple_idxs) if is_non_empty.item()]\n",
    "    },\n",
    "    f'multiple_reg_{save_str}.pth'\n",
    ")\n",
    "# !zip -r optimal_reg_right.zip optimal_reg_right.pth\n",
    "# !zip -r multiple_reg_right.zip multiple_reg_right.pth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cd2f9866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['best_1', 'best_n', 'n', 'combined', 'multiple', 'best_1_files', 'best_n_files', 'combined_files', 'multiple_files'])\n",
      "44 176 44 520\n"
     ]
    }
   ],
   "source": [
    "data = torch.load(f'multiple_reg_{save_str}.pth')\n",
    "print(data.keys())\n",
    "print(len(data['best_1_files']), len(data['best_n_files']), len(data['combined_files']), len(data['multiple_files']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a7839d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['crossmoda_102_ceT1_l.nii.gz:var0', 'crossmoda_102_ceT1_l.nii.gz:var1', 'crossmoda_102_ceT1_l.nii.gz:var2', 'crossmoda_102_ceT1_l.nii.gz:var3', 'crossmoda_103_ceT1_l.nii.gz:var0', 'crossmoda_103_ceT1_l.nii.gz:var1', 'crossmoda_103_ceT1_l.nii.gz:var2', 'crossmoda_103_ceT1_l.nii.gz:var3', 'crossmoda_104_ceT1_l.nii.gz:var0', 'crossmoda_104_ceT1_l.nii.gz:var1', 'crossmoda_104_ceT1_l.nii.gz:var2', 'crossmoda_104_ceT1_l.nii.gz:var3', 'crossmoda_105_ceT1_l.nii.gz:var0', 'crossmoda_105_ceT1_l.nii.gz:var1', 'crossmoda_105_ceT1_l.nii.gz:var2', 'crossmoda_105_ceT1_l.nii.gz:var3', 'crossmoda_10_ceT1_l.nii.gz:var0', 'crossmoda_10_ceT1_l.nii.gz:var1', 'crossmoda_10_ceT1_l.nii.gz:var2', 'crossmoda_10_ceT1_l.nii.gz:var3', 'crossmoda_13_ceT1_l.nii.gz:var0', 'crossmoda_13_ceT1_l.nii.gz:var1', 'crossmoda_13_ceT1_l.nii.gz:var2', 'crossmoda_13_ceT1_l.nii.gz:var3', 'crossmoda_14_ceT1_l.nii.gz:var0', 'crossmoda_14_ceT1_l.nii.gz:var1', 'crossmoda_14_ceT1_l.nii.gz:var2', 'crossmoda_14_ceT1_l.nii.gz:var3', 'crossmoda_15_ceT1_l.nii.gz:var0', 'crossmoda_15_ceT1_l.nii.gz:var1', 'crossmoda_15_ceT1_l.nii.gz:var2', 'crossmoda_15_ceT1_l.nii.gz:var3', 'crossmoda_18_ceT1_l.nii.gz:var0', 'crossmoda_18_ceT1_l.nii.gz:var1', 'crossmoda_18_ceT1_l.nii.gz:var2', 'crossmoda_18_ceT1_l.nii.gz:var3', 'crossmoda_20_ceT1_l.nii.gz:var0', 'crossmoda_20_ceT1_l.nii.gz:var1', 'crossmoda_20_ceT1_l.nii.gz:var2', 'crossmoda_20_ceT1_l.nii.gz:var3', 'crossmoda_21_ceT1_l.nii.gz:var0', 'crossmoda_21_ceT1_l.nii.gz:var1', 'crossmoda_21_ceT1_l.nii.gz:var2', 'crossmoda_21_ceT1_l.nii.gz:var3', 'crossmoda_22_ceT1_l.nii.gz:var0', 'crossmoda_22_ceT1_l.nii.gz:var1', 'crossmoda_22_ceT1_l.nii.gz:var2', 'crossmoda_22_ceT1_l.nii.gz:var3', 'crossmoda_26_ceT1_l.nii.gz:var0', 'crossmoda_26_ceT1_l.nii.gz:var1', 'crossmoda_26_ceT1_l.nii.gz:var2', 'crossmoda_26_ceT1_l.nii.gz:var3', 'crossmoda_28_ceT1_l.nii.gz:var0', 'crossmoda_28_ceT1_l.nii.gz:var1', 'crossmoda_28_ceT1_l.nii.gz:var2', 'crossmoda_28_ceT1_l.nii.gz:var3', 'crossmoda_2_ceT1_l.nii.gz:var0', 'crossmoda_2_ceT1_l.nii.gz:var1', 'crossmoda_2_ceT1_l.nii.gz:var2', 'crossmoda_2_ceT1_l.nii.gz:var3', 'crossmoda_31_ceT1_l.nii.gz:var0', 'crossmoda_31_ceT1_l.nii.gz:var1', 'crossmoda_31_ceT1_l.nii.gz:var2', 'crossmoda_31_ceT1_l.nii.gz:var3', 'crossmoda_34_ceT1_l.nii.gz:var0', 'crossmoda_34_ceT1_l.nii.gz:var1', 'crossmoda_34_ceT1_l.nii.gz:var2', 'crossmoda_34_ceT1_l.nii.gz:var3', 'crossmoda_38_ceT1_l.nii.gz:var0', 'crossmoda_38_ceT1_l.nii.gz:var1', 'crossmoda_38_ceT1_l.nii.gz:var2', 'crossmoda_38_ceT1_l.nii.gz:var3', 'crossmoda_41_ceT1_l.nii.gz:var0', 'crossmoda_41_ceT1_l.nii.gz:var1', 'crossmoda_41_ceT1_l.nii.gz:var2', 'crossmoda_41_ceT1_l.nii.gz:var3', 'crossmoda_42_ceT1_l.nii.gz:var0', 'crossmoda_42_ceT1_l.nii.gz:var1', 'crossmoda_42_ceT1_l.nii.gz:var2', 'crossmoda_42_ceT1_l.nii.gz:var3', 'crossmoda_43_ceT1_l.nii.gz:var0', 'crossmoda_43_ceT1_l.nii.gz:var1', 'crossmoda_43_ceT1_l.nii.gz:var2', 'crossmoda_43_ceT1_l.nii.gz:var3', 'crossmoda_49_ceT1_l.nii.gz:var0', 'crossmoda_49_ceT1_l.nii.gz:var1', 'crossmoda_49_ceT1_l.nii.gz:var2', 'crossmoda_49_ceT1_l.nii.gz:var3', 'crossmoda_51_ceT1_l.nii.gz:var0', 'crossmoda_51_ceT1_l.nii.gz:var1', 'crossmoda_51_ceT1_l.nii.gz:var2', 'crossmoda_51_ceT1_l.nii.gz:var3', 'crossmoda_55_ceT1_l.nii.gz:var0', 'crossmoda_55_ceT1_l.nii.gz:var1', 'crossmoda_55_ceT1_l.nii.gz:var2', 'crossmoda_55_ceT1_l.nii.gz:var3', 'crossmoda_56_ceT1_l.nii.gz:var0', 'crossmoda_56_ceT1_l.nii.gz:var1', 'crossmoda_56_ceT1_l.nii.gz:var2', 'crossmoda_56_ceT1_l.nii.gz:var3', 'crossmoda_58_ceT1_l.nii.gz:var0', 'crossmoda_58_ceT1_l.nii.gz:var1', 'crossmoda_58_ceT1_l.nii.gz:var2', 'crossmoda_58_ceT1_l.nii.gz:var3', 'crossmoda_61_ceT1_l.nii.gz:var0', 'crossmoda_61_ceT1_l.nii.gz:var1', 'crossmoda_61_ceT1_l.nii.gz:var2', 'crossmoda_61_ceT1_l.nii.gz:var3', 'crossmoda_62_ceT1_l.nii.gz:var0', 'crossmoda_62_ceT1_l.nii.gz:var1', 'crossmoda_62_ceT1_l.nii.gz:var2', 'crossmoda_62_ceT1_l.nii.gz:var3', 'crossmoda_63_ceT1_l.nii.gz:var0', 'crossmoda_63_ceT1_l.nii.gz:var1', 'crossmoda_63_ceT1_l.nii.gz:var2', 'crossmoda_63_ceT1_l.nii.gz:var3', 'crossmoda_64_ceT1_l.nii.gz:var0', 'crossmoda_64_ceT1_l.nii.gz:var1', 'crossmoda_64_ceT1_l.nii.gz:var2', 'crossmoda_64_ceT1_l.nii.gz:var3', 'crossmoda_66_ceT1_l.nii.gz:var0', 'crossmoda_66_ceT1_l.nii.gz:var1', 'crossmoda_66_ceT1_l.nii.gz:var2', 'crossmoda_66_ceT1_l.nii.gz:var3', 'crossmoda_67_ceT1_l.nii.gz:var0', 'crossmoda_67_ceT1_l.nii.gz:var1', 'crossmoda_67_ceT1_l.nii.gz:var2', 'crossmoda_67_ceT1_l.nii.gz:var3', 'crossmoda_69_ceT1_l.nii.gz:var0', 'crossmoda_69_ceT1_l.nii.gz:var1', 'crossmoda_69_ceT1_l.nii.gz:var2', 'crossmoda_69_ceT1_l.nii.gz:var3', 'crossmoda_71_ceT1_l.nii.gz:var0', 'crossmoda_71_ceT1_l.nii.gz:var1', 'crossmoda_71_ceT1_l.nii.gz:var2', 'crossmoda_71_ceT1_l.nii.gz:var3', 'crossmoda_75_ceT1_l.nii.gz:var0', 'crossmoda_75_ceT1_l.nii.gz:var1', 'crossmoda_75_ceT1_l.nii.gz:var2', 'crossmoda_75_ceT1_l.nii.gz:var3', 'crossmoda_79_ceT1_l.nii.gz:var0', 'crossmoda_79_ceT1_l.nii.gz:var1', 'crossmoda_79_ceT1_l.nii.gz:var2', 'crossmoda_79_ceT1_l.nii.gz:var3', 'crossmoda_81_ceT1_l.nii.gz:var0', 'crossmoda_81_ceT1_l.nii.gz:var1', 'crossmoda_81_ceT1_l.nii.gz:var2', 'crossmoda_81_ceT1_l.nii.gz:var3', 'crossmoda_87_ceT1_l.nii.gz:var0', 'crossmoda_87_ceT1_l.nii.gz:var1', 'crossmoda_87_ceT1_l.nii.gz:var2', 'crossmoda_87_ceT1_l.nii.gz:var3', 'crossmoda_88_ceT1_l.nii.gz:var0', 'crossmoda_88_ceT1_l.nii.gz:var1', 'crossmoda_88_ceT1_l.nii.gz:var2', 'crossmoda_88_ceT1_l.nii.gz:var3', 'crossmoda_89_ceT1_l.nii.gz:var0', 'crossmoda_89_ceT1_l.nii.gz:var1', 'crossmoda_89_ceT1_l.nii.gz:var2', 'crossmoda_89_ceT1_l.nii.gz:var3', 'crossmoda_8_ceT1_l.nii.gz:var0', 'crossmoda_8_ceT1_l.nii.gz:var1', 'crossmoda_8_ceT1_l.nii.gz:var2', 'crossmoda_8_ceT1_l.nii.gz:var3', 'crossmoda_90_ceT1_l.nii.gz:var0', 'crossmoda_90_ceT1_l.nii.gz:var1', 'crossmoda_90_ceT1_l.nii.gz:var2', 'crossmoda_90_ceT1_l.nii.gz:var3', 'crossmoda_93_ceT1_l.nii.gz:var0', 'crossmoda_93_ceT1_l.nii.gz:var1', 'crossmoda_93_ceT1_l.nii.gz:var2', 'crossmoda_93_ceT1_l.nii.gz:var3', 'crossmoda_99_ceT1_l.nii.gz:var0', 'crossmoda_99_ceT1_l.nii.gz:var1', 'crossmoda_99_ceT1_l.nii.gz:var2', 'crossmoda_99_ceT1_l.nii.gz:var3']\n"
     ]
    }
   ],
   "source": [
    "print(data['best_n_files'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65841530",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l optimal_reg_right.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d478a11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('after',after.mean(0),after.max(0)[0],after.min(0)[0],)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5e511e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45f4bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5,10):\n",
    "    print(dice_coeff(seg3d[fix,8:-56,48:-16,40:-24],(combined[:,:,:,1]>i).squeeze().cpu(),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3388cd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(combined[:,:,32,1])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9d9ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_centre = torch.zeros(3,60)\n",
    "cross_dice = torch.zeros(31,60,2)\n",
    "\n",
    "all_warped2 = torch.zeros(31,96,96,96)#all_warped[2]/all_warped[3]*31\n",
    "\n",
    "\n",
    "for nu1 in range(31):\n",
    "    all_disp = torch.zeros(31,96,96,96,3)\n",
    "    all_warped = torch.zeros(4,96,96,96)\n",
    "    grid = torch.stack(torch.meshgrid((torch.arange(96),torch.arange(96),torch.arange(96)))).float()\n",
    "    #print(grid.shape)\n",
    "    centre0 = torch.sum(grid.view(3,-1)*(seg2d_t2[nu1*96:(1+nu1)*96]==2).view(1,-1).float(),1)/torch.sum(seg2d_t2[nu1*96:(1+nu1)*96]==2)\n",
    "    all_dice = torch.zeros(2)\n",
    "    torch.cuda.synchronize()\n",
    "    t0 = time.time()\n",
    "    for nu in range(60):\n",
    "        img_fixed = img2d_t2[nu1*96:(1+nu1)*96].view(96,96,96)\n",
    "        img_moving = img2d[nu*96:(nu+1)*96].view(96,96,96)\n",
    "        \n",
    "        all_disp[nu] = disp\n",
    "        warped = F.grid_sample(seg2d[nu*96:(nu+1)*96].float().cuda().view(1,1,96,96,96),F.affine_grid(torch.eye(3,4).cuda().unsqueeze(0),(1,1,96,96,96))+disp.cuda(),mode='nearest')\n",
    "        warped_onehot = F.grid_sample(F.one_hot(seg2d[nu*96:(nu+1)*96],3).permute(3,0,1,2).float().cuda().view(1,3,96,96,96),F.affine_grid(torch.eye(3,4).cuda().unsqueeze(0),(1,1,96,96,96))+disp.cuda(),mode='bilinear')\n",
    "        warped_mind = F.grid_sample(mindssc_mov.float(),F.affine_grid(torch.eye(3,4).cuda().unsqueeze(0),(1,1,96,96,96))+disp.cuda(),mode='bilinear')\n",
    "\n",
    "\n",
    "        similarity = torch.exp(-1.5*F.avg_pool3d((mindssc_fix-warped_mind).pow(2),1,stride=1,padding=0).sum(1).squeeze(0))\n",
    "\n",
    "\n",
    "        #print(dice_coeff(seg2d[nu1*96:(1+nu1)*96],seg2d_t2[nu*96:(nu+1)*96],3))\n",
    "        #nib.save(nib.Nifti1Image(warped.squeeze().byte().cpu().data.numpy(),np.eye(4)),'crossmoda_reg_F'+str(nu1)+'_T2_M'+str(nu)+'_T1.nii.gz')\n",
    "        all_warped[:3] += (similarity*warped_onehot).squeeze(0).cpu()#F.one_hot(warped.squeeze().long(),3).cpu().permute(3,0,1,2)\n",
    "        all_warped[3] += similarity.squeeze().cpu()\n",
    "        d = (dice_coeff(seg2d_t2[nu1*96:(1+nu1)*96],warped.squeeze().cpu(),3))\n",
    "        all_dice += d\n",
    "        cross_dice[nu1,nu] = d\n",
    "    centre = torch.sum(grid.view(3,-1)*(all_warped[2]).view(1,-1).float(),1)/torch.sum(all_warped[2])\n",
    "    print('localisation',centre,(centre-centre0).norm(),'dice',all_dice/40)\n",
    "    torch.cuda.synchronize()\n",
    "    t1 = time.time()\n",
    "    print('time for 31 registrations',t1-t0,'sec')\n",
    "    all_centre[:,nu1] = centre\n",
    "    all_warped2[nu1] = all_warped[2]/all_warped[3]*31\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
