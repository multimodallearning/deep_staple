{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/how-to-use-the-staple-algorithm-to-combine-multiple-image-segmentations-ce91ebeb451e\n",
    "# packages\n",
    "import nibabel as nib # https://nipy.org/nibabel/\n",
    "import SimpleITK as sitk # https://simpleitk.org/\n",
    "from matplotlib import pyplot as plt\n",
    "from meidic_vtach_utils.run_on_recommended_cuda import get_cuda_environ_vars as get_vars\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Debug: STAPLEImageFilter (0x55ec92cdd6b0): Executing ITK filter:\n",
      "STAPLEImageFilter (0x7ff7c8020ab0)\n",
      "  RTTI typeinfo:   itk::STAPLEImageFilter<itk::Image<short, 3u>, itk::Image<double, 3u> >\n",
      "  Reference Count: 1\n",
      "  Modified Time: 21215\n",
      "  Debug: Off\n",
      "  Object Name: \n",
      "  Observers: \n",
      "    DeleteEvent(FunctionCommand)\n",
      "  Inputs: \n",
      "    Primary: (0x55ec92cee350) *\n",
      "    _1: (0x55ec49e23280)\n",
      "    _2: (0x55ec9461a3f0)\n",
      "    _3: (0x55ec92c95c90)\n",
      "    _4: (0x55ec928774a0)\n",
      "    _5: (0x55ec92ba1700)\n",
      "    _6: (0x55ec92c32140)\n",
      "    _7: (0x55ec9282db30)\n",
      "    _8: (0x55ec92cb4c30)\n",
      "    _9: (0x55ec928d34d0)\n",
      "  Indexed Inputs: \n",
      "    0: Primary (0x55ec92cee350)\n",
      "    1: _1 (0x55ec49e23280)\n",
      "    2: _2 (0x55ec9461a3f0)\n",
      "    3: _3 (0x55ec92c95c90)\n",
      "    4: _4 (0x55ec928774a0)\n",
      "    5: _5 (0x55ec92ba1700)\n",
      "    6: _6 (0x55ec92c32140)\n",
      "    7: _7 (0x55ec9282db30)\n",
      "    8: _8 (0x55ec92cb4c30)\n",
      "    9: _9 (0x55ec928d34d0)\n",
      "  Required Input Names: Primary\n",
      "  NumberOfRequiredInputs: 1\n",
      "  Outputs: \n",
      "    Primary: (0x55ec94410560)\n",
      "  Indexed Outputs: \n",
      "    0: Primary (0x55ec94410560)\n",
      "  NumberOfRequiredOutputs: 1\n",
      "  Number Of Work Units: 40\n",
      "  ReleaseDataFlag: Off\n",
      "  ReleaseDataBeforeUpdateFlag: Off\n",
      "  AbortGenerateData: Off\n",
      "  Progress: 0\n",
      "  Multithreader: \n",
      "    RTTI typeinfo:   itk::PlatformMultiThreader\n",
      "    Reference Count: 1\n",
      "    Modified Time: 21185\n",
      "    Debug: Off\n",
      "    Object Name: \n",
      "    Observers: \n",
      "      none\n",
      "    Number of Work Units: 40\n",
      "    Number of Threads: 40\n",
      "    Global Maximum Number Of Threads: 128\n",
      "    Global Default Number Of Threads: 40\n",
      "    Global Default Threader Type: itk::MultiThreaderBaseEnums::Threader::Platform\n",
      "    SingleMethod: 0\n",
      "    SingleData: 0\n",
      "  DynamicMultiThreading: On\n",
      "  CoordinateTolerance: 1e-06\n",
      "  DirectionTolerance: 1e-06\n",
      "  m_MaximumIterations = 4294967295\n",
      "  m_ForegroundValue = 1\n",
      "  m_ConfidenceWeight = 1\n",
      "  m_ElapsedIterations = 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reg_state = \"acummulate_deeds_FT2_MT1\"\n",
    "\n",
    "staple_filter = sitk.STAPLEImageFilter()\n",
    "# sitk.ProcessObject.SetGlobalDefaultDebugOff()\n",
    "FOREGROUND = 1.0\n",
    "weight_data = {}\n",
    "EVERY = 3\n",
    "staple_filter.SetForegroundValue(FOREGROUND)\n",
    "DATA_PATH = \"/share/data_supergrover1/weihsbach/shared_data/important_data_artifacts/curriculum_deeplab/20220114_crossmoda_multiple_registrations/crossmoda_deeds_registered.pth\"\n",
    "DEBUG = True\n",
    "\n",
    "if reg_state == \"acummulate_deeds_FT2_MT1\":\n",
    "    bare_data = torch.load(DATA_PATH)\n",
    "    for fixed_id, moving_dict in bare_data.items():\n",
    "        moving_data = []\n",
    "        # loaded_identifier = []\n",
    "        selected_moving_ids = []\n",
    "        sorted_moving_dict = OrderedDict(moving_dict)\n",
    "        for idx_mov, (moving_id, moving_sample) in enumerate(sorted_moving_dict.items()):\n",
    "            # Only use every third warped sample\n",
    "            if idx_mov % EVERY == 0:\n",
    "                moving_data.append(moving_sample['warped_label'].cpu())\n",
    "                selected_moving_ids.append(moving_id)\n",
    "                # loaded_identifier.append(f\"{fixed_id}:m{moving_id}\")\n",
    "        sitk_moving_data = [sitk.GetImageFromArray(reg_seg.to_dense().numpy().astype(np.int16)) for reg_seg in moving_data]\n",
    "    \n",
    "        staple_out = staple_filter.Execute(sitk_moving_data)\n",
    "        # staple_out = sitk.STAPLE(sitk_moving_data, FOREGROUND)\n",
    "        consensus = sitk.GetArrayFromImage(staple_out)\n",
    "        \n",
    "        specitivity = staple_filter.GetSpecificity()\n",
    "        sensitivity = staple_filter.GetSensitivity()\n",
    "        f_weight_dict = weight_data.get(fixed_id, {})\n",
    "        staple_consensus = sitk.GetArrayFromImage(staple_out)\n",
    "\n",
    "        for moving_id, sens, spec in zip(selected_moving_ids, sensitivity, specitivity):\n",
    "            f_weight_dict[moving_id] = dict(sensitivity=sens, specitivity=spec)\n",
    "        weight_data[fixed_id] = f_weight_dict\n",
    "        \n",
    "        if DEBUG: break\n",
    "else:\n",
    "    raise ValueError()\n",
    "\n",
    "weight_data['data_path'] = DATA_PATH\n",
    "torch.save(weight_data, f\"./data/staple_calc/{reg_state}_every_{EVERY}.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['108r', 'data_path'])\n",
      "dict_keys(['100r', '012r', '019r', '024r', '029r', '033r', '037r', '040r', '045r', '048r'])\n",
      "dict_keys(['sensitivity', 'specitivity'])\n",
      "0.7385671312894508\n"
     ]
    }
   ],
   "source": [
    "print(weight_data.keys())\n",
    "print(weight_data['108r'].keys())\n",
    "print(weight_data['108r']['100r'].keys())\n",
    "print(weight_data['108r']['100r']['sensitivity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "06ba18e7235aac9e9578e5cb0339dda8530a2db7f5b95196862af1240ab4b857"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
